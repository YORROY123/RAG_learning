{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac0a8a8c-b55c-4dac-ad41-b29582ce03cf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# åŸºæ–¼langchainå‰µå»ºè‡ªå·±å°ˆå±¬çš„å°è©±å¤§æ¨¡å‹\n",
    "## 1.é ˜åŸŸç²¾æº–å•ç­”\n",
    "## 2.æ•¸æ“šæ›´æ–°é »ç¹\n",
    "## 3.ç”Ÿæˆå…§å®¹å¯è§£é‡‹å¯è¿½æº¯\n",
    "## 4.æ•¸æ“šéš±ç§ä¿è­·\n",
    "\n",
    "#### é€šéé€™å€‹ä¾‹å­ï¼Œæˆ‘å€‘å°‡åŸºæ–¼LangChainï¼ŒOpenAI(LLM)ï¼Œvector DBå»ºæ§‹ä¸€å€‹å±¬æ–¼è‡ªå·±çš„LLMæ¨¡å‹ã€‚\n",
    "#### ä¸»è¦ä½¿ç”¨çš„æŠ€è¡“----Retrieval Augmented Generation (RAG)\n",
    "#### é¦–å…ˆç¢ºä¿è‡ªå·±æ“æœ‰çš„ä¸€å€‹ OpenAI API key (ä¹Ÿä¸¦ééœ€è¦)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42cce94-f44f-4963-baee-9b36696981b5",
   "metadata": {},
   "source": [
    "### æº–å‚™ç’°å¢ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bb4a1e8-a9d5-4401-b0ac-b0570c69df3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "elasticsearch7 7.17.12 requires urllib3<2,>=1.21.1, but you have urllib3 2.3.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "! pip install -qU \\\n",
    "    langchain==0.0.316 \\\n",
    "    openai==0.28.1 \\\n",
    "    tiktoken==0.5.1 \\\n",
    "    cohere \\\n",
    "    chromadb==0.4.15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bea0ee-8f20-449b-8936-60fbddc00b17",
   "metadata": {},
   "source": [
    "### å‰µå»ºä¸€å€‹å°è©±æ¨¡å‹(no RAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cb4baf-0d55-4d56-ab7a-33ef167280da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65e0a19-64ce-434c-af17-e2bf40f9c8a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd96bcd2-ac7d-41cb-a7c2-de49bab3d905",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… API å‘¼å«æˆåŠŸï¼Œå›å‚³å…§å®¹å¦‚ä¸‹ï¼š\n",
      "{\n",
      "  \"id\": \"gen-1744262757-R189lbVuM9rpL7A0krmP\",\n",
      "  \"provider\": \"Chutes\",\n",
      "  \"model\": \"mistralai/mistral-small-3.1-24b-instruct\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1744262757,\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"native_finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"\\u7576\\u7136\\u53ef\\u4ee5\\uff01\\u8cbb\\u6c0f\\u6578\\u5217\\u662f\\u4e00\\u500b\\u8457\\u540d\\u7684\\u6578\\u5b78\\u5e8f\\u5217\\uff0c\\u5176\\u4e2d\\u6bcf\\u500b\\u6578\\u5b57\\u662f\\u524d\\u5169\\u500b\\u6578\\u5b57\\u7684\\u7e3d\\u548c\\u3002\\u901a\\u5e38\\u5f9e0\\u548c1\\u62161\\u548c1\\u958b\\u59cb\\u3002\\u4ee5\\u4e0b\\u662f\\u4e00\\u6bb5Python\\u7a0b\\u5f0f\\u78bc\\uff0c\\u8a08\\u7b97\\u8cbb\\u6c0f\\u6578\\u5217\\u7684\\u524dN\\u500b\\u6578\\u5b57\\uff1a\\n\\n```python\\ndef fibonacci(n):\\n    if n <= 0:\\n        return []\\n    elif n == 1:\\n        return [0]\\n    elif n == 2:\\n        return [0, 1]\\n\\n    fib_sequence = [0, 1]\\n    for i in range(2, n):\\n        next_value = fib_sequence[-1] + fib_sequence[-2]\\n        fib_sequence.append(next_value)\\n\\n    return fib_sequence\\n\\n# \\u7bc4\\u4f8b\\u4f7f\\u7528\\nn = 10  # \\u5047\\u8a2d\\u6211\\u5011\\u8981\\u8a08\\u7b97\\u524d10\\u500b\\u8cbb\\u6c0f\\u6578\\u5217\\u6578\\u5b57\\nfib_sequence = fibonacci(n)\\nprint(f\\\"The first {n} Fibonacci numbers are: {fib_sequence}\\\")\\n```\\n\\n\\u9019\\u6bb5\\u7a0b\\u5f0f\\u78bc\\u5b9a\\u7fa9\\u4e86\\u4e00\\u500b\\u51fd\\u6578 `fibonacci(n)`\\uff0c\\u6703\\u8fd4\\u56de\\u8cbb\\u6c0f\\u6578\\u5217\\u7684\\u524dN\\u500b\\u6578\\u5b57\\u3002\\u4f60\\u53ef\\u4ee5\\u6839\\u64da\\u9700\\u8981\\u4fee\\u6539 `n` \\u7684\\u503c\\u4f86\\u8a08\\u7b97\\u4e0d\\u540c\\u9577\\u5ea6\\u7684\\u8cbb\\u6c0f\\u6578\\u5217\\u3002\",\n",
      "        \"refusal\": null,\n",
      "        \"reasoning\": null\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 198,\n",
      "    \"completion_tokens\": 274,\n",
      "    \"total_tokens\": 472\n",
      "  }\n",
      "}\n",
      "âœ… æ¨¡å‹å›è¦†å…§å®¹ï¼š\n",
      "ç•¶ç„¶å¯ä»¥ï¼è²»æ°æ•¸åˆ—æ˜¯ä¸€å€‹è‘—åçš„æ•¸å­¸åºåˆ—ï¼Œå…¶ä¸­æ¯å€‹æ•¸å­—æ˜¯å‰å…©å€‹æ•¸å­—çš„ç¸½å’Œã€‚é€šå¸¸å¾0å’Œ1æˆ–1å’Œ1é–‹å§‹ã€‚ä»¥ä¸‹æ˜¯ä¸€æ®µPythonç¨‹å¼ç¢¼ï¼Œè¨ˆç®—è²»æ°æ•¸åˆ—çš„å‰Nå€‹æ•¸å­—ï¼š\n",
      "\n",
      "```python\n",
      "def fibonacci(n):\n",
      "    if n <= 0:\n",
      "        return []\n",
      "    elif n == 1:\n",
      "        return [0]\n",
      "    elif n == 2:\n",
      "        return [0, 1]\n",
      "\n",
      "    fib_sequence = [0, 1]\n",
      "    for i in range(2, n):\n",
      "        next_value = fib_sequence[-1] + fib_sequence[-2]\n",
      "        fib_sequence.append(next_value)\n",
      "\n",
      "    return fib_sequence\n",
      "\n",
      "# ç¯„ä¾‹ä½¿ç”¨\n",
      "n = 10  # å‡è¨­æˆ‘å€‘è¦è¨ˆç®—å‰10å€‹è²»æ°æ•¸åˆ—æ•¸å­—\n",
      "fib_sequence = fibonacci(n)\n",
      "print(f\"The first {n} Fibonacci numbers are: {fib_sequence}\")\n",
      "```\n",
      "\n",
      "é€™æ®µç¨‹å¼ç¢¼å®šç¾©äº†ä¸€å€‹å‡½æ•¸ `fibonacci(n)`ï¼Œæœƒè¿”å›è²»æ°æ•¸åˆ—çš„å‰Nå€‹æ•¸å­—ã€‚ä½ å¯ä»¥æ ¹æ“šéœ€è¦ä¿®æ”¹ `n` çš„å€¼ä¾†è¨ˆç®—ä¸åŒé•·åº¦çš„è²»æ°æ•¸åˆ—ã€‚\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "# è¨­å®š OpenRouter çš„ API é‡‘é‘°èˆ‡ç¶²å€\n",
    "openai.api_key = \"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\"  # â† è¨˜å¾—\n",
    "openai.api_base = \"https://openrouter.ai/api/v1\"\n",
    "\n",
    "# å‘¼å« API\n",
    "try:\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"mistralai/mistral-small-3.1-24b-instruct:free\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"å¹«æˆ‘å¯«ä¸€æ®µ Python ç¨‹å¼ç¢¼ï¼Œè¨ˆç®—è²»æ°æ•¸åˆ—ã€‚\"},\n",
    "        ]\n",
    "    )\n",
    "    print(\"âœ… API å‘¼å«æˆåŠŸï¼Œå›å‚³å…§å®¹å¦‚ä¸‹ï¼š\")\n",
    "    print(json.dumps(response, indent=2))  # ğŸ” å°å‡ºå®Œæ•´ response çµæ§‹ï¼Œå¹«åŠ©é™¤éŒ¯\n",
    "\n",
    "    # å˜—è©¦å–å¾—å…§å®¹\n",
    "    if \"choices\" in response:\n",
    "        content = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "        print(\"âœ… æ¨¡å‹å›è¦†å…§å®¹ï¼š\")\n",
    "        print(content)\n",
    "    else:\n",
    "        print(\"âš ï¸ API å›å‚³ä¸­æ²’æœ‰ 'choices' æ¬„ä½ï¼Œå¯èƒ½æ˜¯éŒ¯èª¤è¨Šæ¯\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ç™¼ç”ŸéŒ¯èª¤ï¼š{e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "afad254e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"gen-1744262757-R189lbVuM9rpL7A0krmP\",\n",
      "  \"provider\": \"Chutes\",\n",
      "  \"model\": \"mistralai/mistral-small-3.1-24b-instruct\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1744262757,\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"native_finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"\\u7576\\u7136\\u53ef\\u4ee5\\uff01\\u8cbb\\u6c0f\\u6578\\u5217\\u662f\\u4e00\\u500b\\u8457\\u540d\\u7684\\u6578\\u5b78\\u5e8f\\u5217\\uff0c\\u5176\\u4e2d\\u6bcf\\u500b\\u6578\\u5b57\\u662f\\u524d\\u5169\\u500b\\u6578\\u5b57\\u7684\\u7e3d\\u548c\\u3002\\u901a\\u5e38\\u5f9e0\\u548c1\\u62161\\u548c1\\u958b\\u59cb\\u3002\\u4ee5\\u4e0b\\u662f\\u4e00\\u6bb5Python\\u7a0b\\u5f0f\\u78bc\\uff0c\\u8a08\\u7b97\\u8cbb\\u6c0f\\u6578\\u5217\\u7684\\u524dN\\u500b\\u6578\\u5b57\\uff1a\\n\\n```python\\ndef fibonacci(n):\\n    if n <= 0:\\n        return []\\n    elif n == 1:\\n        return [0]\\n    elif n == 2:\\n        return [0, 1]\\n\\n    fib_sequence = [0, 1]\\n    for i in range(2, n):\\n        next_value = fib_sequence[-1] + fib_sequence[-2]\\n        fib_sequence.append(next_value)\\n\\n    return fib_sequence\\n\\n# \\u7bc4\\u4f8b\\u4f7f\\u7528\\nn = 10  # \\u5047\\u8a2d\\u6211\\u5011\\u8981\\u8a08\\u7b97\\u524d10\\u500b\\u8cbb\\u6c0f\\u6578\\u5217\\u6578\\u5b57\\nfib_sequence = fibonacci(n)\\nprint(f\\\"The first {n} Fibonacci numbers are: {fib_sequence}\\\")\\n```\\n\\n\\u9019\\u6bb5\\u7a0b\\u5f0f\\u78bc\\u5b9a\\u7fa9\\u4e86\\u4e00\\u500b\\u51fd\\u6578 `fibonacci(n)`\\uff0c\\u6703\\u8fd4\\u56de\\u8cbb\\u6c0f\\u6578\\u5217\\u7684\\u524dN\\u500b\\u6578\\u5b57\\u3002\\u4f60\\u53ef\\u4ee5\\u6839\\u64da\\u9700\\u8981\\u4fee\\u6539 `n` \\u7684\\u503c\\u4f86\\u8a08\\u7b97\\u4e0d\\u540c\\u9577\\u5ea6\\u7684\\u8cbb\\u6c0f\\u6578\\u5217\\u3002\",\n",
      "        \"refusal\": null,\n",
      "        \"reasoning\": null\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 198,\n",
      "    \"completion_tokens\": 274,\n",
      "    \"total_tokens\": 472\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(response, indent=2))  # é€™å€‹å°å‡ºä¾†çš„çµæœ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2187ebe9-cca5-42d3-badd-7d0d21f02900",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os \n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR-API-KEY\"\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    openai_api_key = os.environ[\"OPENAI_API_KEY\"],\n",
    "    model = 'gpt-3.5-turbo'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e096c1b7-e3c7-4b6d-89ef-7dd8f836c5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import (\n",
    "    SystemMessage,\n",
    "    HumanMessage,\n",
    "    AIMessage\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content = \"Knock knock.\"),\n",
    "    AIMessage(content = \"Who's there?\"),\n",
    "    HumanMessage(content=\"Orange\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f2afff4a-e7e4-4cc4-ac50-f46492b41dd2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "No auth credentials found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m res\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages\\langchain\\chat_models\\base.py:606\u001b[0m, in \u001b[0;36mBaseChatModel.__call__\u001b[1;34m(self, messages, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m    600\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    601\u001b[0m     messages: List[BaseMessage],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    605\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m--> 606\u001b[0m     generation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m    607\u001b[0m         [messages], stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    608\u001b[0m     )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    609\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(generation, ChatGeneration):\n\u001b[0;32m    610\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages\\langchain\\chat_models\\base.py:355\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[0;32m    353\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[0;32m    354\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e)\n\u001b[1;32m--> 355\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    356\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    357\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[0;32m    359\u001b[0m ]\n\u001b[0;32m    360\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages\\langchain\\chat_models\\base.py:345\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    344\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 345\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    346\u001b[0m                 m,\n\u001b[0;32m    347\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    348\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    349\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    350\u001b[0m             )\n\u001b[0;32m    351\u001b[0m         )\n\u001b[0;32m    352\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    353\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages\\langchain\\chat_models\\base.py:498\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    494\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    495\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    496\u001b[0m     )\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported:\n\u001b[1;32m--> 498\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m    499\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    500\u001b[0m     )\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages\\langchain\\chat_models\\openai.py:360\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[1;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[0;32m    358\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[0;32m    359\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[1;32m--> 360\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompletion_with_retry(\n\u001b[0;32m    361\u001b[0m     messages\u001b[38;5;241m=\u001b[39mmessage_dicts, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    362\u001b[0m )\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages\\langchain\\chat_models\\openai.py:299\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry\u001b[1;34m(self, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_completion_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _completion_with_retry(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages\\tenacity\\__init__.py:336\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    334\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    335\u001b[0m wrapped_f\u001b[38;5;241m.\u001b[39mstatistics \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mstatistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m--> 336\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m copy(f, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages\\tenacity\\__init__.py:475\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    473\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 475\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    477\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages\\tenacity\\__init__.py:376\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    374\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[1;32m--> 376\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages\\tenacity\\__init__.py:398\u001b[0m, in \u001b[0;36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[1;34m(rs)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetryCallState\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mis_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mretry_run_result):\n\u001b[1;32m--> 398\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutcome\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    399\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    401\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages\\tenacity\\__init__.py:478\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 478\u001b[0m         result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[0;32m    480\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages\\langchain\\chat_models\\openai.py:297\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry.<locals>._completion_with_retry\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_completion_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m--> 297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:155\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    139\u001b[0m ):\n\u001b[0;32m    140\u001b[0m     (\n\u001b[0;32m    141\u001b[0m         deployment_id,\n\u001b[0;32m    142\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    152\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    153\u001b[0m     )\n\u001b[1;32m--> 155\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[0;32m    166\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[0;32m    167\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages\\openai\\api_requestor.py:299\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    280\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    287\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    288\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    289\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[0;32m    290\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[0;32m    291\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    297\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[0;32m    298\u001b[0m     )\n\u001b[1;32m--> 299\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    300\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages\\openai\\api_requestor.py:710\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    702\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    703\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    704\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    705\u001b[0m         )\n\u001b[0;32m    706\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[0;32m    707\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    708\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    709\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 710\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    711\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    712\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    714\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    715\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    716\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    717\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages\\openai\\api_requestor.py:775\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    773\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m    774\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m--> 775\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[0;32m    776\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[0;32m    777\u001b[0m     )\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mAuthenticationError\u001b[0m: No auth credentials found"
     ]
    }
   ],
   "source": [
    "res = chat(messages)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61112f7-f8af-4145-8f6c-50c0d039a0f8",
   "metadata": {},
   "source": [
    "## ç”¨OpenRouterçš„ mistralai/mistral-small-3.1-24b-instruct:free èªè¨€æ¨¡å‹ å¯¦ä½œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a16050f9-74e8-45a8-8a62-cfa05f2372a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import (\n",
    "    SystemMessage,\n",
    "    HumanMessage,\n",
    "    AIMessage\n",
    ")\n",
    "import os\n",
    "\n",
    "# è¨­å®š API é‡‘é‘°èˆ‡ OpenRouter çš„ base url\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "# å»ºç«‹ ChatOpenAIï¼Œæ”¯æ´ OpenRouter\n",
    "chat = ChatOpenAI(\n",
    "    openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    openai_api_base=\"https://openrouter.ai/api/v1\",\n",
    "    model=\"mistralai/mistral-small-3.1-24b-instruct:free\"\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3d23584e-9327-4563-8705-7f5b6424db37",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'choices'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 10\u001b[0m\n\u001b[0;32m      2\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      3\u001b[0m     SystemMessage(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a helpful assistant.\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      4\u001b[0m     HumanMessage(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mæ•²æ•²é–€\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      5\u001b[0m     AIMessage(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mèª°åœ¨æ?\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      6\u001b[0m     HumanMessage(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mæˆ‘å•¦ï¼Œäººé¡\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      7\u001b[0m ]\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# ç™¼é€å°è©±\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# å°å‡ºå›ç­”\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(res\u001b[38;5;241m.\u001b[39mcontent)\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages\\langchain\\chat_models\\base.py:606\u001b[0m, in \u001b[0;36mBaseChatModel.__call__\u001b[1;34m(self, messages, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m    600\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    601\u001b[0m     messages: List[BaseMessage],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    605\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m--> 606\u001b[0m     generation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m    607\u001b[0m         [messages], stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    608\u001b[0m     )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    609\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(generation, ChatGeneration):\n\u001b[0;32m    610\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages\\langchain\\chat_models\\base.py:355\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[0;32m    353\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[0;32m    354\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e)\n\u001b[1;32m--> 355\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    356\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    357\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[0;32m    359\u001b[0m ]\n\u001b[0;32m    360\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages\\langchain\\chat_models\\base.py:345\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    344\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 345\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    346\u001b[0m                 m,\n\u001b[0;32m    347\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    348\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    349\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    350\u001b[0m             )\n\u001b[0;32m    351\u001b[0m         )\n\u001b[0;32m    352\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    353\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages\\langchain\\chat_models\\base.py:498\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    494\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    495\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    496\u001b[0m     )\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported:\n\u001b[1;32m--> 498\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m    499\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    500\u001b[0m     )\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages\\langchain\\chat_models\\openai.py:363\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[1;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[0;32m    359\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[0;32m    360\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompletion_with_retry(\n\u001b[0;32m    361\u001b[0m     messages\u001b[38;5;241m=\u001b[39mmessage_dicts, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    362\u001b[0m )\n\u001b[1;32m--> 363\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_chat_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages\\langchain\\chat_models\\openai.py:378\u001b[0m, in \u001b[0;36mChatOpenAI._create_chat_result\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_create_chat_result\u001b[39m(\u001b[38;5;28mself\u001b[39m, response: Mapping[\u001b[38;5;28mstr\u001b[39m, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatResult:\n\u001b[0;32m    377\u001b[0m     generations \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 378\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchoices\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[0;32m    379\u001b[0m         message \u001b[38;5;241m=\u001b[39m convert_dict_to_message(res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    380\u001b[0m         gen \u001b[38;5;241m=\u001b[39m ChatGeneration(\n\u001b[0;32m    381\u001b[0m             message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[0;32m    382\u001b[0m             generation_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(finish_reason\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinish_reason\u001b[39m\u001b[38;5;124m\"\u001b[39m)),\n\u001b[0;32m    383\u001b[0m         )\n",
      "\u001b[1;31mKeyError\u001b[0m: 'choices'"
     ]
    }
   ],
   "source": [
    "# å¤šè¼ªå°è©±è¨Šæ¯ï¼ˆSystemã€Userã€AI æ¨¡æ“¬æ­·å²å°è©±ï¼‰\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"æ•²æ•²é–€\"),\n",
    "    AIMessage(content=\"èª°åœ¨æ?\"),\n",
    "    HumanMessage(content=\"æˆ‘å•¦ï¼Œäººé¡\"),\n",
    "]\n",
    "\n",
    "# ç™¼é€å°è©±\n",
    "res = chat(messages)\n",
    "\n",
    "# å°å‡ºå›ç­”\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3bd994d5-ef90-4e91-bbe3-53aacd56f508",
   "metadata": {},
   "outputs": [],
   "source": [
    "## é‡æ–°å„²å­˜ æ–°å°è©±\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"Knock knock.\"),\n",
    "    AIMessage(content=\"Who's there?\"),\n",
    "    HumanMessage(content=\"Orange\"),\n",
    "    AIMessage(content=\"Orange who? Orange you going to let me in?\"),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42ecd550-88e4-4a45-ab52-34ffdf0902c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It seems we are playing a game of knock knock!\n",
      "\n",
      "So let's start again.\n",
      "\n",
      "Knock knock.\n",
      "\n",
      "(You go!)\n"
     ]
    }
   ],
   "source": [
    "# æ–°å¢ä¸€è¼ªå°è©±\n",
    "messages.append(HumanMessage(content=\"Who's there?\"))\n",
    "\n",
    "# ç™¼é€å°è©±ä¸¦å°å‡ºå›ç­”\n",
    "response = chat(messages)\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c19a1bb-4835-4596-9269-a8faae5c224e",
   "metadata": {},
   "source": [
    "## è™•ç†LLMå­˜åœ¨çš„ç¼ºé™·\n",
    "\n",
    "### 1.å®¹æ˜“å‡ºç¾å¹»è¦º\n",
    "### 2.ä¿¡æ¯æ»¯å¾Œ\n",
    "### 3.å°ˆæ¥­é ˜åŸŸæ·±åº¦åŒ±ä¹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5857a467-08ea-4713-8ae0-a5529aae5ce4",
   "metadata": {},
   "source": [
    "#### æ–°çš„å°è©±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcb9b653-a6f4-46bb-a5d7-989d34254255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ˜¯çš„ï¼Œæˆ‘çŸ¥é“ ChatGPT æ¨¡å‹ã€‚ChatGPT æ˜¯ç”± OpenAI å¼€å‘çš„ä¸€æ¬¾åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„å¯¹è¯ç”Ÿæˆç³»ç»Ÿã€‚å®ƒåˆ©ç”¨æ·±åº¦å­¦ä¹ æŠ€æœ¯ï¼Œç‰¹åˆ«æ˜¯å˜æ¢å™¨ï¼ˆTransformerï¼‰æ¶æ„ï¼Œæ¥ç†è§£å’Œç”Ÿæˆè‡ªç„¶è¯­è¨€æ–‡æœ¬ã€‚ChatGPT èƒ½å¤Ÿè¿›è¡Œå¤šç§å¯¹è¯ä»»åŠ¡ï¼ŒåŒ…æ‹¬å›ç­”é—®é¢˜ã€æä¾›ä¿¡æ¯ã€ç¼–å†™æ–‡æœ¬ã€ç¿»è¯‘è¯­è¨€ç­‰ã€‚\n",
      "\n",
      "ChatGPT çš„è®­ç»ƒæ•°æ®æ¥æºäºå¤§é‡çš„äº’è”ç½‘æ–‡æœ¬ï¼Œå› æ­¤å®ƒèƒ½å¤Ÿå¤„ç†å¹¿æ³›çš„ä¸»é¢˜å’Œé—®é¢˜ã€‚ç„¶è€Œï¼Œå®ƒçš„çŸ¥è¯†æˆªæ­¢åˆ°2023å¹´10æœˆï¼Œæ— æ³•å®æ—¶è·å–æœ€æ–°çš„ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œå®ƒå¯èƒ½ä¼šåœ¨æŸäº›æƒ…å†µä¸‹ç”Ÿæˆä¸å‡†ç¡®æˆ–ä¸å¯é çš„ä¿¡æ¯ï¼Œå› æ­¤ä½¿ç”¨æ—¶éœ€è¦è°¨æ…ã€‚\n",
      "\n",
      "å¦‚æœä½ æœ‰ä»»ä½•å…·ä½“çš„é—®é¢˜æˆ–éœ€è¦è¿›ä¸€æ­¥çš„ä¿¡æ¯ï¼Œè¯·å‘Šè¯‰æˆ‘ï¼\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„çŸ¥è­˜åŠ©æ‰‹ã€‚\"),\n",
    "    HumanMessage(content=\"ä½ çŸ¥é“chatgptæ¨¡å‹å—?\"),\n",
    "]\n",
    "\n",
    "res = chat(messages)\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92c4af2-6763-4969-8efa-37c83741c319",
   "metadata": {},
   "source": [
    "### å…¶å¯¦æœ‰ç™¼ç¾mistralai/mistral-small-3.1-24b-instruct:free èªè¨€æ¨¡å‹ç„¡æ³•æ»¿è¶³æˆ‘å€‘åœ¨æŸäº›ç‰¹å®šé ˜åŸŸçš„å°ˆæ¥­éœ€æ±‚ï¼Œæˆ‘å€‘å¯ä»¥é€šéçŸ¥è­˜æ³¨å…¥çš„æ–¹å¼ï¼Œåˆ©ç”¨promptä¾†è§£æ±ºå•é¡Œ:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4ffca2-0c9c-4ed8-8c21-18ed91183c85",
   "metadata": {},
   "source": [
    "<img src=\"picture/wiki.jpg\" width=\"800\" height=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4f0f38c5-3b7a-4e46-949b-903b1a420afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ChatGPT_information = [\n",
    "    \"ChatGPTï¼Œå…¨ç¨±èŠå¤©ç”Ÿæˆé è¨“ç·´è½‰æ›å™¨ï¼ˆè‹±èªï¼šChat Generative Pre-trained Transformerï¼‰ï¼Œæ˜¯OpenAIé–‹ç™¼çš„äººå·¥æ™ºæ…§èŠå¤©æ©Ÿå™¨äººç¨‹å¼ï¼Œæ–¼2022å¹´12æœˆæ¨å‡ºã€‚\",\n",
    "    \"è©²ç¨‹å¼ä½¿ç”¨åŸºæ–¼GPT-3.5ã€GPT-4ã€GPT-4oã€GPT-4.5æ¶æ§‹çš„å¤§å‹èªè¨€æ¨¡å‹ä¸¦ä»¥å¼·åŒ–å­¸ç¿’è¨“ç·´ã€‚\",\n",
    "    \"ChatGPTç›®å‰ä»ä»¥æ–‡å­—æ–¹å¼äº’å‹•ï¼Œè€Œé™¤äº†å¯ä»¥ç”¨äººé¡è‡ªç„¶å°è©±æ–¹å¼ä¾†äº’å‹•ï¼Œé‚„å¯ä»¥ç”¨æ–¼ç”šç‚ºè¤‡é›œçš„èªè¨€å·¥ä½œï¼ŒåŒ…æ‹¬è‡ªå‹•ç”Ÿæˆæ–‡å­—ã€è‡ªå‹•å•ç­”ã€è‡ªå‹•æ‘˜è¦ç­‰å¤šç¨®ä»»å‹™ã€‚\",\n",
    "    \"å¦‚ï¼šåœ¨è‡ªå‹•æ–‡å­—ç”Ÿæˆæ–¹é¢ï¼ŒChatGPTå¯ä»¥æ ¹æ“šè¼¸å…¥çš„æ–‡å­—è‡ªå‹•ç”Ÿæˆé¡ä¼¼çš„æ–‡å­—ï¼ˆåŠ‡æœ¬ã€æ­Œæ›²ã€ä¼åŠƒç­‰ï¼‰ï¼Œåœ¨è‡ªå‹•å•ç­”æ–¹é¢ï¼ŒChatGPTå¯ä»¥æ ¹æ“šè¼¸å…¥çš„å•é¡Œè‡ªå‹•ç”Ÿæˆç­”æ¡ˆã€‚\",\n",
    "    \"é‚„æœ‰ç·¨å¯«å’Œé™¤éŒ¯é›»è…¦ç¨‹å¼çš„èƒ½åŠ›ã€‚\",\n",
    "    \"åœ¨æ¨å»£æœŸé–“ï¼Œæ‰€æœ‰äººå¯ä»¥å…è²»è¨»å†Šï¼Œä¸¦åœ¨ç™»å…¥å¾Œå…è²»ä½¿ç”¨ChatGPTèˆ‡AIæ©Ÿå™¨äººå°è©±ã€‚\",\n",
    "    \"ChatGPTå¯å¯«å‡ºç›¸ä¼¼çœŸäººçš„æ–‡ç« ï¼Œä¸¦åœ¨è¨±å¤šçŸ¥è­˜é ˜åŸŸçµ¦å‡ºè©³ç´°å’Œæ¸…æ™°çš„å›ç­”è€Œè¿…é€Ÿç²å¾—é—œæ³¨ï¼Œè­‰æ˜äº†å¾å‰èªç‚ºAIä¸æœƒå–ä»£çš„çŸ¥è­˜å‹å·¥ä½œå®ƒä¹Ÿè¶³ä»¥å‹ä»»ï¼Œå°é‡‘èèˆ‡ç™½é ˜äººåŠ›å¸‚å ´çš„è¡æ“Šç›¸ç•¶å¤§ï¼Œä¸¦åœ¨é€æ­¥æå‡å–ä»£é†«ç™‚äººåŠ›çš„èƒ½åŠ›ï¼Œä»¥æä¾›æ¯”äººé¡æ›´ä½³çš„è¨ºæ–·ã€‚\",\n",
    "    \"ä½†ä¹Ÿèªç‚ºäº‹å¯¦æº–ç¢ºåº¦åƒå·®ä¸é½Šæ˜¯å…¶é‡å¤§ç¼ºé™·ï¼Œä¸¦èªç‚ºåŸºæ–¼æ„è­˜å½¢æ…‹çš„æ¨¡å‹è¨“ç·´çµæœé ˆå°å¿ƒæ ¡æ­£ã€‚\",\n",
    "    \"ChatGPTæ–¼2022å¹´12æœˆç™¼å¸ƒå¾Œï¼ŒOpenAIä¼°å€¼å·²æ¼²è‡³290å„„ç¾å…ƒã€‚\",\n",
    "    \"ä¸Šç·š5å¤©å¾Œå·²æœ‰100è¬ä½¿ç”¨è€…ï¼Œä¸Šç·šå…©å€‹æœˆå¾Œå·²æœ‰ä¸Šå„„ä½¿ç”¨è€…ã€‚\",\n",
    "    \"ç›®å‰GPT-3.5ï¼ˆç¾å‡ç´šç‚ºGPT-4o miniï¼‰ç‚ºå…è²»ä½¿ç”¨ï¼Œç„¡éœ€è¨»å†Šï¼ŒGPT-4oå°å·²è¨»å†Šå…è²»ä½¿ç”¨è€…é–‹æ”¾ä½¿ç”¨ï¼Œä½†æœ‰ä½¿ç”¨é‡é™åˆ¶ã€‚\",\n",
    "    \"è¨»å†Šçš„ChatGPTå…è²»ä½¿ç”¨è€…éƒ½å¯ä»¥ä½¿ç”¨ç€è¦½ã€è¦–è¦ºã€è³‡æ–™åˆ†æã€æª”æ¡ˆä¸Šå‚³å’ŒGPTsç­‰åŸä»˜è²»ä½¿ç”¨è€…çš„åŠŸèƒ½ï¼Œä½†æœ‰ä½¿ç”¨é‡é™åˆ¶ã€‚\",\n",
    "    \"é›–ç„¶ChatGPTåœ¨ç”Ÿæˆé¡äººæ–‡å­—æ–¹é¢è¡¨ç¾å‡ºäº†å“è¶Šçš„èƒ½åŠ›ï¼Œä½†å®ƒå€‘å¾ˆå®¹æ˜“ç¹¼æ‰¿å’Œæ”¾å¤§è¨“ç·´è³‡æ–™ä¸­å­˜åœ¨çš„åå·®ã€‚\",\n",
    "    \"é€™å¯èƒ½è¡¨ç¾ç‚ºå°ä¸åŒäººå£çµ±è¨ˆè³‡æ–™çš„æ­ªæ›²è¡¨è¿°æˆ–ä¸å…¬å¹³å¾…é‡ï¼Œä¾‹å¦‚åŸºæ–¼ç¨®æ—ã€æ€§åˆ¥ã€èªè¨€å’Œæ–‡åŒ–ç¾¤é«”çš„ä¸åŒè§€é»èˆ‡æ…‹åº¦ã€‚\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "826de2b6-cacb-43a3-9acb-2d49f2c04f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_knowledge = \"\\n\".join(ChatGPT_information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f6b7db5e-9b87-427d-898a-11fed28ec2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPTï¼Œå…¨ç¨±èŠå¤©ç”Ÿæˆé è¨“ç·´è½‰æ›å™¨ï¼ˆè‹±èªï¼šChat Generative Pre-trained Transformerï¼‰ï¼Œæ˜¯OpenAIé–‹ç™¼çš„äººå·¥æ™ºæ…§èŠå¤©æ©Ÿå™¨äººç¨‹å¼ï¼Œæ–¼2022å¹´12æœˆæ¨å‡ºã€‚\n",
      "è©²ç¨‹å¼ä½¿ç”¨åŸºæ–¼GPT-3.5ã€GPT-4ã€GPT-4oã€GPT-4.5æ¶æ§‹çš„å¤§å‹èªè¨€æ¨¡å‹ä¸¦ä»¥å¼·åŒ–å­¸ç¿’è¨“ç·´ã€‚\n",
      "ChatGPTç›®å‰ä»ä»¥æ–‡å­—æ–¹å¼äº’å‹•ï¼Œè€Œé™¤äº†å¯ä»¥ç”¨äººé¡è‡ªç„¶å°è©±æ–¹å¼ä¾†äº’å‹•ï¼Œé‚„å¯ä»¥ç”¨æ–¼ç”šç‚ºè¤‡é›œçš„èªè¨€å·¥ä½œï¼ŒåŒ…æ‹¬è‡ªå‹•ç”Ÿæˆæ–‡å­—ã€è‡ªå‹•å•ç­”ã€è‡ªå‹•æ‘˜è¦ç­‰å¤šç¨®ä»»å‹™ã€‚\n",
      "å¦‚ï¼šåœ¨è‡ªå‹•æ–‡å­—ç”Ÿæˆæ–¹é¢ï¼ŒChatGPTå¯ä»¥æ ¹æ“šè¼¸å…¥çš„æ–‡å­—è‡ªå‹•ç”Ÿæˆé¡ä¼¼çš„æ–‡å­—ï¼ˆåŠ‡æœ¬ã€æ­Œæ›²ã€ä¼åŠƒç­‰ï¼‰ï¼Œåœ¨è‡ªå‹•å•ç­”æ–¹é¢ï¼ŒChatGPTå¯ä»¥æ ¹æ“šè¼¸å…¥çš„å•é¡Œè‡ªå‹•ç”Ÿæˆç­”æ¡ˆã€‚\n",
      "é‚„æœ‰ç·¨å¯«å’Œé™¤éŒ¯é›»è…¦ç¨‹å¼çš„èƒ½åŠ›ã€‚\n",
      "åœ¨æ¨å»£æœŸé–“ï¼Œæ‰€æœ‰äººå¯ä»¥å…è²»è¨»å†Šï¼Œä¸¦åœ¨ç™»å…¥å¾Œå…è²»ä½¿ç”¨ChatGPTèˆ‡AIæ©Ÿå™¨äººå°è©±ã€‚\n",
      "ChatGPTå¯å¯«å‡ºç›¸ä¼¼çœŸäººçš„æ–‡ç« ï¼Œä¸¦åœ¨è¨±å¤šçŸ¥è­˜é ˜åŸŸçµ¦å‡ºè©³ç´°å’Œæ¸…æ™°çš„å›ç­”è€Œè¿…é€Ÿç²å¾—é—œæ³¨ï¼Œè­‰æ˜äº†å¾å‰èªç‚ºAIä¸æœƒå–ä»£çš„çŸ¥è­˜å‹å·¥ä½œå®ƒä¹Ÿè¶³ä»¥å‹ä»»ï¼Œå°é‡‘èèˆ‡ç™½é ˜äººåŠ›å¸‚å ´çš„è¡æ“Šç›¸ç•¶å¤§ï¼Œä¸¦åœ¨é€æ­¥æå‡å–ä»£é†«ç™‚äººåŠ›çš„èƒ½åŠ›ï¼Œä»¥æä¾›æ¯”äººé¡æ›´ä½³çš„è¨ºæ–·ã€‚\n",
      "ä½†ä¹Ÿèªç‚ºäº‹å¯¦æº–ç¢ºåº¦åƒå·®ä¸é½Šæ˜¯å…¶é‡å¤§ç¼ºé™·ï¼Œä¸¦èªç‚ºåŸºæ–¼æ„è­˜å½¢æ…‹çš„æ¨¡å‹è¨“ç·´çµæœé ˆå°å¿ƒæ ¡æ­£ã€‚\n",
      "ChatGPTæ–¼2022å¹´12æœˆç™¼å¸ƒå¾Œï¼ŒOpenAIä¼°å€¼å·²æ¼²è‡³290å„„ç¾å…ƒã€‚\n",
      "ä¸Šç·š5å¤©å¾Œå·²æœ‰100è¬ä½¿ç”¨è€…ï¼Œä¸Šç·šå…©å€‹æœˆå¾Œå·²æœ‰ä¸Šå„„ä½¿ç”¨è€…ã€‚\n",
      "ç›®å‰GPT-3.5ï¼ˆç¾å‡ç´šç‚ºGPT-4o miniï¼‰ç‚ºå…è²»ä½¿ç”¨ï¼Œç„¡éœ€è¨»å†Šï¼ŒGPT-4oå°å·²è¨»å†Šå…è²»ä½¿ç”¨è€…é–‹æ”¾ä½¿ç”¨ï¼Œä½†æœ‰ä½¿ç”¨é‡é™åˆ¶ã€‚\n",
      "è¨»å†Šçš„ChatGPTå…è²»ä½¿ç”¨è€…éƒ½å¯ä»¥ä½¿ç”¨ç€è¦½ã€è¦–è¦ºã€è³‡æ–™åˆ†æã€æª”æ¡ˆä¸Šå‚³å’ŒGPTsç­‰åŸä»˜è²»ä½¿ç”¨è€…çš„åŠŸèƒ½ï¼Œä½†æœ‰ä½¿ç”¨é‡é™åˆ¶ã€‚\n",
      "é›–ç„¶ChatGPTåœ¨ç”Ÿæˆé¡äººæ–‡å­—æ–¹é¢è¡¨ç¾å‡ºäº†å“è¶Šçš„èƒ½åŠ›ï¼Œä½†å®ƒå€‘å¾ˆå®¹æ˜“ç¹¼æ‰¿å’Œæ”¾å¤§è¨“ç·´è³‡æ–™ä¸­å­˜åœ¨çš„åå·®ã€‚\n",
      "é€™å¯èƒ½è¡¨ç¾ç‚ºå°ä¸åŒäººå£çµ±è¨ˆè³‡æ–™çš„æ­ªæ›²è¡¨è¿°æˆ–ä¸å…¬å¹³å¾…é‡ï¼Œä¾‹å¦‚åŸºæ–¼ç¨®æ—ã€æ€§åˆ¥ã€èªè¨€å’Œæ–‡åŒ–ç¾¤é«”çš„ä¸åŒè§€é»èˆ‡æ…‹åº¦ã€‚\n"
     ]
    }
   ],
   "source": [
    "print(source_knowledge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7957a5d7-96a0-4260-a17e-8743a52f47fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"ä½ çŸ¥é“ChatGPTæ¨¡å‹å—\"\n",
    "prompt_template = f\"\"\"åŸºæ–¼ä»¥ä¸‹å…§å®¹å›ç­”å•é¡Œ:\n",
    "å…§å®¹:\n",
    "{source_knowledge}\n",
    "\n",
    "Query: {query}\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "49dd1350-fdc2-421a-b6ac-b293403c87b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = HumanMessage(\n",
    "    content = prompt_template\n",
    ")\n",
    "messages.append(prompt)\n",
    "\n",
    "res = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "14fb35ad-ae4d-4a54-b45b-eee7122e9b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ˜¯çš„ï¼Œæˆ‘çŸ¥é“ChatGPTæ¨¡å‹ã€‚ChatGPTæ˜¯ç”±OpenAIé–‹ç™¼çš„ä¸€ç¨®åŸºæ–¼GPTï¼ˆGenerative Pre-trained Transformerï¼‰æ¶æ§‹çš„å¤§å‹èªè¨€æ¨¡å‹ï¼Œæ—¨åœ¨é€²è¡Œè‡ªç„¶èªè¨€è™•ç†å’Œç”Ÿæˆã€‚ä»¥ä¸‹æ˜¯ä¸€äº›é—œéµé»ï¼š\n",
      "\n",
      "1. **ç™¼å¸ƒæ™‚é–“**ï¼šChatGPTæ–¼2022å¹´12æœˆæ¨å‡ºã€‚\n",
      "2. **æŠ€è¡“åŸºç¤**ï¼šChatGPTåŸºæ–¼GPT-3.5ã€GPT-4ã€GPT-4oå’ŒGPT-4.5ç­‰æ¶æ§‹ï¼Œä¸¦é€šéå¼·åŒ–å­¸ç¿’é€²è¡Œè¨“ç·´ã€‚\n",
      "3. **åŠŸèƒ½**ï¼šChatGPTèƒ½å¤ é€²è¡Œå¤šç¨®èªè¨€ä»»å‹™ï¼ŒåŒ…æ‹¬è‡ªå‹•ç”Ÿæˆæ–‡å­—ã€è‡ªå‹•å•ç­”ã€è‡ªå‹•æ‘˜è¦ã€ç·¨å¯«å’Œé™¤éŒ¯é›»è…¦ç¨‹å¼ç­‰ã€‚\n",
      "4. **ä½¿ç”¨æ–¹å¼**ï¼šç›®å‰ChatGPTä¸»è¦é€šéæ–‡å­—æ–¹å¼èˆ‡ç”¨æˆ¶äº’å‹•ï¼Œèƒ½å¤ æ¨¡æ“¬äººé¡è‡ªç„¶å°è©±ã€‚\n",
      "5. **æ‡‰ç”¨ç¯„åœ**ï¼šChatGPTå¯ä»¥ç”¨æ–¼å¤šç¨®çŸ¥è­˜å‹å·¥ä½œï¼ŒåŒ…æ‹¬åŠ‡æœ¬ã€æ­Œæ›²ã€ä¼åŠƒçš„ç”Ÿæˆï¼Œä¸¦èƒ½åœ¨é‡‘èã€é†«ç™‚ç­‰é ˜åŸŸæä¾›æ”¯æŒã€‚\n",
      "6. **å…è²»ä½¿ç”¨**ï¼šåœ¨æ¨å»£æœŸé–“ï¼Œæ‰€æœ‰äººå¯ä»¥å…è²»è¨»å†Šä¸¦ä½¿ç”¨ChatGPTã€‚GPT-3.5ï¼ˆç¾å‡ç´šç‚ºGPT-4o miniï¼‰ç‚ºå…è²»ä½¿ç”¨ï¼ŒGPT-4oå‰‡å°å·²è¨»å†Šå…è²»ä½¿ç”¨è€…é–‹æ”¾ï¼Œä½†æœ‰ä½¿ç”¨é‡é™åˆ¶ã€‚\n",
      "7. **ç¼ºé™·èˆ‡æŒ‘æˆ°**ï¼šå„˜ç®¡ChatGPTè¡¨ç¾å‡ºè‰²ï¼Œä½†å…¶ç”Ÿæˆçš„å…§å®¹å¯èƒ½å­˜åœ¨äº‹å¯¦æº–ç¢ºåº¦å•é¡Œï¼Œä¸¦å¯èƒ½ç¹¼æ‰¿å’Œæ”¾å¤§è¨“ç·´è³‡æ–™ä¸­çš„åå·®ï¼Œå¦‚ç¨®æ—ã€æ€§åˆ¥ã€èªè¨€å’Œæ–‡åŒ–ç¾¤é«”çš„æ­ªæ›²è¡¨è¿°æˆ–ä¸å…¬å¹³å¾…é‡ã€‚\n",
      "\n",
      "ç¸½çš„ä¾†èªªï¼ŒChatGPTæ˜¯ä¸€ç¨®åŠŸèƒ½å¼·å¤§ä¸”å…·æœ‰å»£æ³›æ‡‰ç”¨å‰æ™¯çš„èªè¨€æ¨¡å‹ï¼Œä½†ä¹Ÿéœ€è¦æ³¨æ„å…¶æ½›åœ¨çš„åå·®å’Œæº–ç¢ºæ€§å•é¡Œã€‚\n"
     ]
    }
   ],
   "source": [
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b1c989-07ef-4718-9ae1-39d2045cd5d7",
   "metadata": {},
   "source": [
    "### ç™¼ç¾ï¼Œç•¶æˆ‘å€‘é€²è¡ŒçŸ¥è­˜çš„æ³¨å…¥å¾Œï¼Œæ¨¡å‹å°±èƒ½å¾ˆå¥½çš„å›ç­”ç›¸é—œå•é¡Œã€‚å¦‚æœæ¯ä¸€å€‹å•é¡Œéƒ½å»ç”¨å¤–éƒ¨çŸ¥è­˜é€²è¡Œå¢å¼·èˆ‡æ‹šè§£çš„è©±ï¼Œé‚£éº¼å›ç­”çš„æº–ç¢ºæ€§å°±èƒ½å¤§å¤§å¢åŠ å—?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cf1ed5-6b4b-4638-b066-d609c02982ce",
   "metadata": {},
   "source": [
    "## å‰µå»ºä¸€å€‹RAGçš„å°è©±æ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6012dd1-ff92-4b81-a0a5-35292db1e2ce",
   "metadata": {},
   "source": [
    "<img src=\"picture/rag flow.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4c6671-bd73-49a8-bee3-2920e20f6e60",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### 1.åŠ è¼‰æ•¸æ“š"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4906aaa1-a004-4885-a115-445b6a1b9d8d",
   "metadata": {},
   "source": [
    "thesis_.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dab1f8f2-22be-4c3c-8846-fafdb25c1517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (5.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from pypdf) (4.13.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "16f88be8-a5d2-4317-bd89-81607c7bd400",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# ç›´æ¥å¯«è·¯å¾‘ï¼Œå‡è¨­ PDF æª”æ¡ˆèˆ‡è…³æœ¬åœ¨åŒä¸€è³‡æ–™å¤¾\n",
    "loader = PyPDFLoader(\"./thesis__.pdf\")\n",
    "\n",
    "# è¼‰å…¥ä¸¦åˆ†å‰²é é¢\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38c0c4bc-5ebd-4e9d-8136-143e8987d73e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='åœ‹ç«‹æˆåŠŸå¤§å­¸ \\nç³»çµ±åŠèˆ¹èˆ¶æ©Ÿé›»å·¥ç¨‹å­¸ç³» \\nç¢©å£«è«–æ–‡ \\nç†±æˆåƒæŠ€è¡“æ–¼é‹°é›»æ± æœªçŸ¥ç†±æºä¹‹é æ¸¬ \\nThe Estimation of Unknown Transient Heat\\nGeneration for Lithium Battery with \\nThermography Techniques  \\nç ” ç©¶ ç”Ÿï¼š æ—å­æš \\næŒ‡å°æ•™æˆï¼š é»ƒæ­£å¼˜ \\nä¸­è¯æ°‘åœ‹ä¸€ç™¾ä¸€åä¸‰å¹´åäºŒæœˆ', metadata={'source': './thesis__.pdf', 'page': 0})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794d6c4f-bed0-4370-b32f-685a22a08157",
   "metadata": {},
   "source": [
    "### 2.çŸ¥è­˜åˆ‡ç‰‡ å°‡æ–‡æª”åˆ†å‰²æˆå‡å‹»çš„å¡Šã€‚ æ¯å€‹å¡Šæ˜¯ä¸€æ®µåŸå§‹æ–‡æœ¬ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a8961cf2-1b06-47f7-8c40-16c867620ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap =50,\n",
    ")\n",
    "\n",
    "docs = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f4ba87a-ba35-4d00-949d-a9ecf7a7ab4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ae8f9b-2024-4b2f-a753-add96db7ed9d",
   "metadata": {},
   "source": [
    "### 3.åˆ©ç”¨embeddingæ¨¡å‹å°æ¯å€‹æ–‡æœ¬ç‰‡æ®µé€²è¡Œå‘é‡åŒ–ï¼Œä¸¦å„²å­˜åˆ°å‘é‡æ•¸æ“šåº«ä¸­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2c728d0d-8d57-42db-9030-ff3e5c862190",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (0.0.316)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (4.0.2)\n",
      "Requirement already satisfied: transformers in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (4.51.1)\n",
      "Requirement already satisfied: chromadb in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (0.4.15)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from langchain) (2.0.40)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from langchain) (3.11.16)\n",
      "Requirement already satisfied: anyio<4.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from langchain) (3.7.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from langchain) (0.6.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.43 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from langchain) (0.0.92)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from langchain) (2.11.3)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from sentence-transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from sentence-transformers) (0.30.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from sentence-transformers) (4.13.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from chromadb) (0.7.3)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from chromadb) (0.115.12)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
      "Requirement already satisfied: posthog>=2.4.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from chromadb) (3.23.0)\n",
      "Requirement already satisfied: pulsar-client>=3.1.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from chromadb) (3.6.1)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from chromadb) (1.21.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from chromadb) (1.31.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from chromadb) (1.31.1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from chromadb) (1.31.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from chromadb) (1.71.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from chromadb) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from chromadb) (0.15.2)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from chromadb) (32.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.19.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from anyio<4.0->langchain) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from anyio<4.0->langchain) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from anyio<4.0->langchain) (1.2.2)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from fastapi>=0.95.2->chromadb) (0.46.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (3.0.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2025.1.31)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
      "Requirement already satisfied: protobuf in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (5.29.4)\n",
      "Requirement already satisfied: sympy in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.6.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.69.2)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.31.1 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.31.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.31.1 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.31.1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.52b1 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.52b1)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from typer>=0.9.0->chromadb) (14.0.0)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.6.3 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.5)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from deprecated>=1.2.6->opentelemetry-api>=1.2.0->chromadb) (1.17.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (2.19.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.5.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install langchain sentence-transformers transformers chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "542de967-3fd3-47e7-b4cc-7e163daa8f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "\n",
    "\n",
    "# åˆ›å»ºHuggingFace embeddingæ¨¡å‹\n",
    "# è¿™é‡Œä½¿ç”¨å¤šè¯­è¨€æ¨¡å‹ï¼Œå¯¹ä¸­æ–‡æ•ˆæœå¾ˆå¥½\n",
    "embed_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    ")\n",
    "\n",
    "# åˆ›å»ºå‘é‡å­˜å‚¨\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=docs, \n",
    "    embedding=embed_model,\n",
    "    collection_name=\"hf_embeddings\",\n",
    "    persist_directory=\"./chroma_db2\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "22a3a6b4-3e9b-429c-8b50-825428a91141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¤ºä¾‹æœç´¢\n",
    "query = \"ä½œè€…ä½¿ç”¨çš„ å•†æ¥­è»Ÿé«”æ˜¯ç”šéº¼?\"\n",
    "results = vectorstore.similarity_search(query, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "78d78520-96d3-423b-aaaf-4662f927996a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='è£è»Ÿé«”å¼·å¤§çš„æ­£ç®—èƒ½åŠ›ä¾†å½Œè£œå‚³çµ±é€†å‘å•é¡Œä¹‹ä¸è¶³ã€‚æœ¬è«–æ–‡æ‰€ä½¿ç”¨çš„å¥—è£\\nè»Ÿé«”ç‚ºä¸‰ç¶­è€¦åˆè¨ˆç®—æµé«”åŠ›å­¸è»Ÿé«”CFD-ACE+ï¼Œè»Ÿé«”ç‚º ESI-GROUP æ‰€ç™¼\\nè¡Œï¼Œå…¶æä¾›äº†ä¸€ç³»åˆ—åŒ…å«å‰è™•ç†(GEOM)ï¼Œæ•¸å€¼è¨ˆç®—(ACE+)åŠå¾Œè™•ç†(VIEW)\\nç­‰ä¸‰å¤§æ¨¡çµ„ï¼Œä½¿å…¶æ“æœ‰å®Œæ•´ä¸”å¼·å¤§çš„æ­£ç®—å•é¡Œè™•ç†èƒ½åŠ›ã€‚ \\nåœ¨ç¬¬äºŒç« åŠç¬¬ä¸‰ç« å¾äººåˆ©ç”¨æ­¤è»Ÿé«”ä¾†æ¨¡æ“¬åœ“æŸ±å‹é‹°é›»æ± å…§éƒ¨ç†±æºç™¼', metadata={'page': 21, 'source': './thesis__.pdf'}),\n",
       " Document(page_content='1 \\n \\nè‡´è¬ \\nåœ¨æˆ‘æ•´å€‹ç ”ç©¶çš„éç¨‹ä¸­ï¼Œé»ƒæ­£å¼˜æ•™æˆçš„æ‚‰å¿ƒæŒ‡å°å’Œç„¡ç§æ”¯æŒè®“æˆ‘æ·±\\næ„Ÿæ¦®å¹¸ï¼Œä¹Ÿè®“æˆ‘å—ç›ŠåŒªæ·ºã€‚å›é¡§é€™æ®µæ™‚é–“ï¼Œæˆ‘å¾ä¸€åå°ç ”ç©¶é ˜åŸŸæ‡µæ‡‚çš„å­¸\\nç”Ÿï¼Œæˆé•·ç‚ºèƒ½å¤ ç¨ç«‹æ€è€ƒå’Œè§£æ±ºå•é¡Œçš„ç ”ç©¶è€…ï¼Œæ›´æˆ–è€…æ˜¯å¯¦é©—å®¤å­¸å¼Ÿå¦¹çš„\\nè«®è©¢å°è±¡(ç¨‹å¼åŠå¯¦é©—)ï¼Œé€™ä¸€åˆ‡éƒ½é›¢ä¸é–‹é»ƒæ•™æˆçš„è€å¿ƒæ•™å°å’ŒæŒçºŒçš„æ¿€å‹µ \\nã€‚æ•™æˆä»¥å…¶è±å¯Œçš„å­¸è­˜ã€åš´è¬¹çš„å­¸è¡“æ…‹åº¦ä»¥åŠå°æ•™è‚²çš„ç†±å¿±ï¼Œä½¿æˆ‘åœ¨å°ˆæ¥­\\né ˜åŸŸä¸Šä¸æ–·ç²¾é€²ã€‚æ¯ç•¶æˆ‘é‡åˆ°å›°é›£æˆ–æ„Ÿåˆ°è¿·èŒ«æ™‚ï¼Œæ•™æˆç¸½æ˜¯æœƒé‡æ–°ä¸æ–·æ¿€\\nå‹µæˆ‘ï¼Œä¸¦åŠæ™‚æä¾›æœ€å…·å»ºè¨­æ€§çš„å»ºè­°æˆ–æ‰¾å°‹å¤–éƒ¨è³‡æºï¼Œå¹«åŠ©æˆ‘æ‰¾åˆ°è§£æ±ºå•\\né¡Œçš„æ–¹å‘(é›»æ± çš„é›»å­¸ã€è‡ªå‹•åŒ–è³‡æ–™å¾Œè™•ç†ã€ç³»çµ±æŒ‡ä»¤)ï¼ŒåŒæ™‚è—‰ç”±æ¥è§¸æ›´\\nå¤šé¢å‘çš„å°ˆæ¥­çŸ¥è­˜ä¾†è§£æ±ºç„¡æ³•ç”±åŸå…ˆæ€è·¯å»è§£æ±ºçš„å•é¡Œã€‚åœ¨é€™æ®µæ™‚é–“è£¡ï¼Œ\\næˆ‘å­¸æœƒäº†å¦‚ä½•å†·éœåˆ†æå•é¡Œã€è’é›†è³‡æ–™ã€æ‰¾å°‹å°ˆå®¶ä¾†æ¢ç´¢ç­”æ¡ˆï¼Œä¸¦å§‹çµ‚ä¿\\næŒå°çŸ¥è­˜çš„æ¸´æ±‚å’Œå°äº‹ç‰©çš„å¥½å¥‡å¿ƒã€‚ \\nä¹Ÿè¬è¬å²±å† ç§‘æŠ€æœ‰é™å…¬å¸é€£å¥•è¼”å‰¯ç†åœ¨å•†æ¥­å¥—è£è»Ÿé«” ESI-CFD çš„åŠŸ\\nèƒ½è«®è©¢ï¼Œç‰¹åˆ¥æ˜¯åœ¨è™•ç†è¤‡é›œåº¦è¼ƒé«˜çš„æš«æ…‹å•é¡Œä¸Šï¼Œç´°å¿ƒå›è¦†æˆ‘ä¸€äº›ä¸å¸¸ä½¿\\nç”¨çš„ç‰¹æ®ŠåŠŸèƒ½ã€‚é‚„æœ‰æ´²é€šèƒ½æºç§‘æŠ€æœ‰é™å…¬å¸æ—å»ºæˆæ¥­å‹™åœ¨é›»æ± å……æ”¾é›»æ¸¬\\nè©¦ä¸»æ©ŸBAT-760B çš„è«®è©¢ï¼Œå”åŠ©æˆ‘æ¶æ§‹å‡ºé›»æ± æ”¾é›»å¯¦é©—ã€‚åŠå¯ŒåŠ›é›»èƒ½æœ‰é™', metadata={'page': 9, 'source': './thesis__.pdf'})]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c6045e-2974-45f8-90bc-74b742b11913",
   "metadata": {},
   "source": [
    "### 5.åŸå§‹queryèˆ‡æª¢ç´¢å¾—åˆ°çš„æ–‡æœ¬çµ„åˆèµ·ä¾†è¼¸å…¥åˆ°èªè¨€æ¨¡å‹ï¼Œå¾—åˆ°æœ€çµ‚çš„å›ç­”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d24fc029-f2ef-4fd4-afdc-706d7343e305",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_prompt(query: str):\n",
    "    # ç²å–top3çš„æ–‡æœ¬ç‰‡æ®µ\n",
    "    results = vectorstore.similarity_search(query, k=3)\n",
    "    source_knowledge = \"\\n\".join([x.page_content for x in results])\n",
    "    # æ§‹å»ºprompt\n",
    "    augmented_prompt = f\"\"\"Using the contexts below, answer the query.\n",
    "\n",
    "    contexts:\n",
    "    {source_knowledge}\n",
    "\n",
    "    query: {query}\"\"\"\n",
    "    return augmented_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f5e0c59d-070d-463d-8213-37bcf250c937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the contexts below, answer the query.\n",
      "\n",
      "    contexts:\n",
      "    è£è»Ÿé«”å¼·å¤§çš„æ­£ç®—èƒ½åŠ›ä¾†å½Œè£œå‚³çµ±é€†å‘å•é¡Œä¹‹ä¸è¶³ã€‚æœ¬è«–æ–‡æ‰€ä½¿ç”¨çš„å¥—è£\n",
      "è»Ÿé«”ç‚ºä¸‰ç¶­è€¦åˆè¨ˆç®—æµé«”åŠ›å­¸è»Ÿé«”CFD-ACE+ï¼Œè»Ÿé«”ç‚º ESI-GROUP æ‰€ç™¼\n",
      "è¡Œï¼Œå…¶æä¾›äº†ä¸€ç³»åˆ—åŒ…å«å‰è™•ç†(GEOM)ï¼Œæ•¸å€¼è¨ˆç®—(ACE+)åŠå¾Œè™•ç†(VIEW)\n",
      "ç­‰ä¸‰å¤§æ¨¡çµ„ï¼Œä½¿å…¶æ“æœ‰å®Œæ•´ä¸”å¼·å¤§çš„æ­£ç®—å•é¡Œè™•ç†èƒ½åŠ›ã€‚ \n",
      "åœ¨ç¬¬äºŒç« åŠç¬¬ä¸‰ç« å¾äººåˆ©ç”¨æ­¤è»Ÿé«”ä¾†æ¨¡æ“¬åœ“æŸ±å‹é‹°é›»æ± å…§éƒ¨ç†±æºç™¼\n",
      "1 \n",
      " \n",
      "è‡´è¬ \n",
      "åœ¨æˆ‘æ•´å€‹ç ”ç©¶çš„éç¨‹ä¸­ï¼Œé»ƒæ­£å¼˜æ•™æˆçš„æ‚‰å¿ƒæŒ‡å°å’Œç„¡ç§æ”¯æŒè®“æˆ‘æ·±\n",
      "æ„Ÿæ¦®å¹¸ï¼Œä¹Ÿè®“æˆ‘å—ç›ŠåŒªæ·ºã€‚å›é¡§é€™æ®µæ™‚é–“ï¼Œæˆ‘å¾ä¸€åå°ç ”ç©¶é ˜åŸŸæ‡µæ‡‚çš„å­¸\n",
      "ç”Ÿï¼Œæˆé•·ç‚ºèƒ½å¤ ç¨ç«‹æ€è€ƒå’Œè§£æ±ºå•é¡Œçš„ç ”ç©¶è€…ï¼Œæ›´æˆ–è€…æ˜¯å¯¦é©—å®¤å­¸å¼Ÿå¦¹çš„\n",
      "è«®è©¢å°è±¡(ç¨‹å¼åŠå¯¦é©—)ï¼Œé€™ä¸€åˆ‡éƒ½é›¢ä¸é–‹é»ƒæ•™æˆçš„è€å¿ƒæ•™å°å’ŒæŒçºŒçš„æ¿€å‹µ \n",
      "ã€‚æ•™æˆä»¥å…¶è±å¯Œçš„å­¸è­˜ã€åš´è¬¹çš„å­¸è¡“æ…‹åº¦ä»¥åŠå°æ•™è‚²çš„ç†±å¿±ï¼Œä½¿æˆ‘åœ¨å°ˆæ¥­\n",
      "é ˜åŸŸä¸Šä¸æ–·ç²¾é€²ã€‚æ¯ç•¶æˆ‘é‡åˆ°å›°é›£æˆ–æ„Ÿåˆ°è¿·èŒ«æ™‚ï¼Œæ•™æˆç¸½æ˜¯æœƒé‡æ–°ä¸æ–·æ¿€\n",
      "å‹µæˆ‘ï¼Œä¸¦åŠæ™‚æä¾›æœ€å…·å»ºè¨­æ€§çš„å»ºè­°æˆ–æ‰¾å°‹å¤–éƒ¨è³‡æºï¼Œå¹«åŠ©æˆ‘æ‰¾åˆ°è§£æ±ºå•\n",
      "é¡Œçš„æ–¹å‘(é›»æ± çš„é›»å­¸ã€è‡ªå‹•åŒ–è³‡æ–™å¾Œè™•ç†ã€ç³»çµ±æŒ‡ä»¤)ï¼ŒåŒæ™‚è—‰ç”±æ¥è§¸æ›´\n",
      "å¤šé¢å‘çš„å°ˆæ¥­çŸ¥è­˜ä¾†è§£æ±ºç„¡æ³•ç”±åŸå…ˆæ€è·¯å»è§£æ±ºçš„å•é¡Œã€‚åœ¨é€™æ®µæ™‚é–“è£¡ï¼Œ\n",
      "æˆ‘å­¸æœƒäº†å¦‚ä½•å†·éœåˆ†æå•é¡Œã€è’é›†è³‡æ–™ã€æ‰¾å°‹å°ˆå®¶ä¾†æ¢ç´¢ç­”æ¡ˆï¼Œä¸¦å§‹çµ‚ä¿\n",
      "æŒå°çŸ¥è­˜çš„æ¸´æ±‚å’Œå°äº‹ç‰©çš„å¥½å¥‡å¿ƒã€‚ \n",
      "ä¹Ÿè¬è¬å²±å† ç§‘æŠ€æœ‰é™å…¬å¸é€£å¥•è¼”å‰¯ç†åœ¨å•†æ¥­å¥—è£è»Ÿé«” ESI-CFD çš„åŠŸ\n",
      "èƒ½è«®è©¢ï¼Œç‰¹åˆ¥æ˜¯åœ¨è™•ç†è¤‡é›œåº¦è¼ƒé«˜çš„æš«æ…‹å•é¡Œä¸Šï¼Œç´°å¿ƒå›è¦†æˆ‘ä¸€äº›ä¸å¸¸ä½¿\n",
      "ç”¨çš„ç‰¹æ®ŠåŠŸèƒ½ã€‚é‚„æœ‰æ´²é€šèƒ½æºç§‘æŠ€æœ‰é™å…¬å¸æ—å»ºæˆæ¥­å‹™åœ¨é›»æ± å……æ”¾é›»æ¸¬\n",
      "è©¦ä¸»æ©ŸBAT-760B çš„è«®è©¢ï¼Œå”åŠ©æˆ‘æ¶æ§‹å‡ºé›»æ± æ”¾é›»å¯¦é©—ã€‚åŠå¯ŒåŠ›é›»èƒ½æœ‰é™\n",
      "ç”¨ç¨‹å¼èªè¨€Python é…åˆæ–‡å­—ç·¨è¼¯è»Ÿé«”Notepad++å°‡æ‰€éœ€ä¹‹ç†±æºç·¨å¯«æ–¼æ–‡å­—\n",
      "æª”.TXTã€‚ \n",
      "(3) æ’°å¯«ä¾›DTF æª”é€£çµçš„DLL æª” ï¼Œ å…±æœ‰å››å€‹DLL æª” ï¼Œ åˆ†åˆ¥æ˜¯EXACTG\n",
      "æ‰€éœ€çš„ DLL æª”ã€DIR æ‰€éœ€çš„ DLL æª”ã€ADJ æ‰€éœ€çš„ DLL æª”åŠ SEN æ‰€éœ€çš„\n",
      "DLL æª”ã€‚EXACTGã€MAINã€SEN çš„DLL æª”å¯ä»¥ä½¿åœ“æŸ±ä¸­ä¸åŒé«”ç©çš„ç¶²æ ¼\n",
      "\n",
      "    query: ä½œè€…ä½¿ç”¨çš„ å•†æ¥­è»Ÿé«”æ˜¯ç”šéº¼?\n"
     ]
    }
   ],
   "source": [
    "print(augment_prompt(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "be2d8c64-4a79-45de-bfde-2e0b7024e81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½œè€…ä½¿ç”¨çš„å•†æ¥­è»Ÿé«”æ˜¯ **ESI-CFD**ã€‚é€™å€‹è»Ÿé«”ç”± ESI Group ç™¼è¡Œï¼Œå…·é«”ä¾†èªªï¼Œä½œè€…ä½¿ç”¨çš„æ˜¯å…¶ä¸‰ç¶­è€¦åˆè¨ˆç®—æµé«”åŠ›å­¸è»Ÿé«” **CFD-ACE+**ã€‚ESI-CFD æä¾›äº†å‰è™•ç†ï¼ˆGEOMï¼‰ã€æ•¸å€¼è¨ˆç®—ï¼ˆACE+ï¼‰åŠå¾Œè™•ç†ï¼ˆVIEWï¼‰ç­‰ä¸‰å¤§æ¨¡çµ„ï¼Œä½¿å…¶æ“æœ‰å®Œæ•´ä¸”å¼·å¤§çš„æ­£ç®—å•é¡Œè™•ç†èƒ½åŠ›ã€‚\n"
     ]
    }
   ],
   "source": [
    "# å‰µå»º prompt\n",
    "prompt = HumanMessage(\n",
    "    content = augment_prompt(query)\n",
    ")\n",
    "\n",
    "messages.append(prompt)\n",
    "\n",
    "res = chat(messages)\n",
    "\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26da11aa-ab15-4af8-adb7-903448f73cf1",
   "metadata": {},
   "source": [
    "## æ²’æœ‰OPENAI api keyæ€éº¼è¾¦ å‰µå»ºä¸€å€‹éopenaiçš„å°è©±æ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772c9366-5963-4a2d-87ca-2530c849aebd",
   "metadata": {},
   "source": [
    "### 1.embeddingæ¨¡å‹\n",
    "### 2.chatæ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aeec31fc-cc2a-4152-bae5-983176ce4293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (4.0.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from sentence-transformers) (4.51.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from sentence-transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from sentence-transformers) (0.30.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from sentence-transformers) (4.13.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "! pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3c820506-2a7e-4925-9abb-dc060ada0c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "model_name= \"sentence-transformers/sentence-t5-large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b867da64-08f3-470c-bbb8-f7bfaa7adc7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hf_xet\n",
      "  Downloading hf_xet-1.0.2-cp37-abi3-win_amd64.whl.metadata (498 bytes)\n",
      "Downloading hf_xet-1.0.2-cp37-abi3-win_amd64.whl (4.1 MB)\n",
      "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.5/4.1 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 3.1/4.1 MB 10.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.1/4.1 MB 9.9 MB/s eta 0:00:00\n",
      "Installing collected packages: hf_xet\n",
      "Successfully installed hf_xet-1.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install hf_xet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9ebc2b95-e170-43e3-a6ae-fc8f3ad4205f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cf3ada57-a7cf-4b98-9fe4-801e854c7c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = HuggingFaceEmbeddings(model_name = model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "aeb27f07-c051-4577-82da-42ed186c7593",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectorstore_hf = Chroma.from_documents(documents=docs, embedding = embedding , collection_name = \"huggingface_embed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffa2c14-c27b-474f-85f4-9fa2554c5296",
   "metadata": {},
   "source": [
    "### ä¹Ÿå¯ä»¥ç”¨GPU(ä¹‹å¾Œå†ç”¨)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06dae3a-4dbd-4148-a407-380dbbd9cf64",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=KW-iKts6E8M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43835247-38e0-43ec-a472-7d8f4cd79679",
   "metadata": {},
   "source": [
    "### å›åˆ°æ­£é¡Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8e00669e-eaa6-4f90-9704-5e13bb46071d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¤ºä¾‹æœç´¢\n",
    "query = \"How large is the baichuan2 vocavulary?\"\n",
    "result = vectorstore_hf.similarity_search(query, k =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "90d3d9ea-1f80-46e0-9a56-2756cdb17b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='Baichuan 2: Open Large-scale Language Models\\nAiyuan Yang, Bin Xiao, Bingning Wang, Borong Zhang, Chao Yin, Chenxu Lv, Da Pan\\nDian Wang, Dong Yan, Fan Yang, Fei Deng, Feng Wang, Feng Liu, Guangwei Ai\\nGuosheng Dong, Haizhou Zhao, Hang Xu, Haoze Sun, Hongda Zhang, Hui Liu, Jiaming Ji\\nJian Xie, Juntao Dai, Kun Fang, Lei Su, Liang Song, Lifeng Liu, Liyun Ru, Luyao Ma\\nMang Wang, Mickel Liu, MingAn Lin, Nuolan Nie, Peidong Guo, Ruiyang Sun', metadata={'page': 0, 'source': 'C:\\\\Users\\\\roy\\\\AppData\\\\Local\\\\Temp\\\\tmplwua9z6z\\\\tmp.pdf'}), Document(page_content='languages, such as Chinese.\\nIn this technical report, we introduce Baichuan\\n2, a series of large-scale multilingual language\\nmodels. Baichuan 2 has two separate models,\\nBaichuan 2-7B with 7 billion parameters and\\nBaichuan 2-13B with 13 billion parameters. Both\\nmodels were trained on 2.6 trillion tokens, which\\nto our knowledge is the largest to date, more than\\ndouble that of Baichuan 1 (Baichuan, 2023b,a).\\nWith such a massive amount of training data,', metadata={'page': 1, 'source': 'C:\\\\Users\\\\roy\\\\AppData\\\\Local\\\\Temp\\\\tmplwua9z6z\\\\tmp.pdf'})]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "524f6ae6-20e4-4d7b-8261-ac0e3ccd4f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_prompt(query: str):\n",
    "    # ç²å–top3çš„æ–‡æœ¬ç‰‡æ®µ\n",
    "    results = vectorstore.similarity_search(query, k=3)\n",
    "    source_knowledge = \"\\n\".join([x.page_content for x in results])\n",
    "    # æ§‹å»ºprompt\n",
    "    augmented_prompt = f\"\"\"Using the contexts below, answer the query.\n",
    "\n",
    "    contexts:\n",
    "    {source_knowledge}\n",
    "\n",
    "    query: {query}\"\"\"\n",
    "    return augmented_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "64e547e8-6656-4332-a20a-cde9a9f5570f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT æ˜¯ OpenAI å¼€å‘çš„ä¸€ç§äººå·¥æ™ºèƒ½èŠå¤©æœºå™¨äººç¨‹åºï¼Œå…¨ç§°ä¸ºèŠå¤©ç”Ÿæˆé¢„è®­ç»ƒè½¬æ¢å™¨ï¼ˆChat Generative Pre-trained Transformerï¼‰ã€‚å®ƒäº 2022 å¹´ 12 æœˆæ¨å‡ºï¼ŒåŸºäº GPT-3.5ã€GPT-4ã€GPT-4oã€GPT-4.5 æ¶æ„çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå¹¶é€šè¿‡å¼ºåŒ–å­¦ä¹ è¿›è¡Œè®­ç»ƒã€‚ChatGPT èƒ½å¤Ÿè¿›è¡Œè‡ªç„¶å¯¹è¯ï¼Œå¹¶å¯ç”¨äºå¤æ‚çš„è¯­è¨€ä»»åŠ¡ï¼Œå¦‚è‡ªåŠ¨ç”Ÿæˆæ–‡å­—ã€è‡ªåŠ¨é—®ç­”å’Œè‡ªåŠ¨æ‘˜è¦ç­‰ã€‚å®ƒè¿˜èƒ½ç¼–å†™å’Œè°ƒè¯•ç”µè„‘ç¨‹åºã€‚\n",
      "\n",
      "ChatGPT çš„æ¨å¹¿æœŸé—´ï¼Œæ‰€æœ‰äººéƒ½å¯ä»¥å…è´¹æ³¨å†Œå¹¶ä½¿ç”¨ã€‚å®ƒèƒ½å¤Ÿç”Ÿæˆç±»ä¼¼çœŸäººçš„æ–‡ç« ï¼Œå¹¶åœ¨è®¸å¤šçŸ¥è¯†é¢†åŸŸæä¾›è¯¦ç»†ä¸”æ¸…æ™°çš„å›ç­”ã€‚ç„¶è€Œï¼ŒChatGPT åœ¨äº‹å®å‡†ç¡®åº¦å’Œæ„è¯†å½¢æ€æ–¹é¢å¯èƒ½å­˜åœ¨åå·®ã€‚\n",
      "\n",
      "å…³äº Baichuan 2 çš„è¯æ±‡é‡ï¼Œæ ¹æ®æä¾›çš„èƒŒæ™¯ä¿¡æ¯ï¼Œå¹¶æ²¡æœ‰ç›´æ¥æåˆ° Baichuan 2 çš„è¯æ±‡é‡å¤§å°ã€‚Baichuan 2 æ˜¯ä¸€ç§å¤§å‹å¤šè¯­è¨€è¯­è¨€æ¨¡å‹ï¼Œæœ‰ä¸¤ä¸ªç‰ˆæœ¬ï¼šBaichuan 2-7Bï¼ˆ70äº¿å‚æ•°ï¼‰å’Œ Baichuan 2-13Bï¼ˆ130äº¿å‚æ•°ï¼‰ï¼Œä¸¤è€…éƒ½åœ¨ 2.6 ä¸‡äº¿ä¸ªè¯æ±‡ä¸Šè¿›è¡Œè®­ç»ƒã€‚å¦‚æœéœ€è¦å…·ä½“çš„è¯æ±‡é‡ä¿¡æ¯ï¼Œå¯èƒ½éœ€è¦å‚è€ƒ Baichuan 2 çš„æŠ€æœ¯æŠ¥å‘Šæˆ–å®˜æ–¹æ–‡æ¡£ã€‚\n"
     ]
    }
   ],
   "source": [
    "# å‰µå»º prompt\n",
    "prompt = HumanMessage(\n",
    "    content = augment_prompt(query)\n",
    ")\n",
    "# åˆ©ç”¨å‰é¢çš„ å¤§èªè¨€æ¨¡å‹ç¹¼çºŒ å•å•é¡Œ\n",
    "messages.append(prompt)\n",
    "\n",
    "res = chat(messages)\n",
    "\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c582b7ba-cd86-4a50-89c2-ef0f20682d56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
