{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac0a8a8c-b55c-4dac-ad41-b29582ce03cf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# 基於langchain創建自己專屬的對話大模型\n",
    "## 1.領域精準問答\n",
    "## 2.數據更新頻繁\n",
    "## 3.生成內容可解釋可追溯\n",
    "## 4.數據隱私保護\n",
    "\n",
    "#### 通過這個例子，我們將基於LangChain，OpenAI(LLM)，vector DB建構一個屬於自己的LLM模型。\n",
    "#### 主要使用的技術----Retrieval Augmented Generation (RAG)\n",
    "#### 首先確保自己擁有的一個 OpenAI API key (也並非需要)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42cce94-f44f-4963-baee-9b36696981b5",
   "metadata": {},
   "source": [
    "### 準備環境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bb4a1e8-a9d5-4401-b0ac-b0570c69df3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "elasticsearch7 7.17.12 requires urllib3<2,>=1.21.1, but you have urllib3 2.3.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "! pip install -qU \\\n",
    "    langchain==0.0.316 \\\n",
    "    openai==0.28.1 \\\n",
    "    tiktoken==0.5.1 \\\n",
    "    cohere \\\n",
    "    chromadb==0.4.15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bea0ee-8f20-449b-8936-60fbddc00b17",
   "metadata": {},
   "source": [
    "### 創建一個對話模型(no RAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cb4baf-0d55-4d56-ab7a-33ef167280da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65e0a19-64ce-434c-af17-e2bf40f9c8a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd96bcd2-ac7d-41cb-a7c2-de49bab3d905",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ API 呼叫成功，回傳內容如下：\n",
      "{\n",
      "  \"id\": \"gen-1744262757-R189lbVuM9rpL7A0krmP\",\n",
      "  \"provider\": \"Chutes\",\n",
      "  \"model\": \"mistralai/mistral-small-3.1-24b-instruct\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1744262757,\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"native_finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"\\u7576\\u7136\\u53ef\\u4ee5\\uff01\\u8cbb\\u6c0f\\u6578\\u5217\\u662f\\u4e00\\u500b\\u8457\\u540d\\u7684\\u6578\\u5b78\\u5e8f\\u5217\\uff0c\\u5176\\u4e2d\\u6bcf\\u500b\\u6578\\u5b57\\u662f\\u524d\\u5169\\u500b\\u6578\\u5b57\\u7684\\u7e3d\\u548c\\u3002\\u901a\\u5e38\\u5f9e0\\u548c1\\u62161\\u548c1\\u958b\\u59cb\\u3002\\u4ee5\\u4e0b\\u662f\\u4e00\\u6bb5Python\\u7a0b\\u5f0f\\u78bc\\uff0c\\u8a08\\u7b97\\u8cbb\\u6c0f\\u6578\\u5217\\u7684\\u524dN\\u500b\\u6578\\u5b57\\uff1a\\n\\n```python\\ndef fibonacci(n):\\n    if n <= 0:\\n        return []\\n    elif n == 1:\\n        return [0]\\n    elif n == 2:\\n        return [0, 1]\\n\\n    fib_sequence = [0, 1]\\n    for i in range(2, n):\\n        next_value = fib_sequence[-1] + fib_sequence[-2]\\n        fib_sequence.append(next_value)\\n\\n    return fib_sequence\\n\\n# \\u7bc4\\u4f8b\\u4f7f\\u7528\\nn = 10  # \\u5047\\u8a2d\\u6211\\u5011\\u8981\\u8a08\\u7b97\\u524d10\\u500b\\u8cbb\\u6c0f\\u6578\\u5217\\u6578\\u5b57\\nfib_sequence = fibonacci(n)\\nprint(f\\\"The first {n} Fibonacci numbers are: {fib_sequence}\\\")\\n```\\n\\n\\u9019\\u6bb5\\u7a0b\\u5f0f\\u78bc\\u5b9a\\u7fa9\\u4e86\\u4e00\\u500b\\u51fd\\u6578 `fibonacci(n)`\\uff0c\\u6703\\u8fd4\\u56de\\u8cbb\\u6c0f\\u6578\\u5217\\u7684\\u524dN\\u500b\\u6578\\u5b57\\u3002\\u4f60\\u53ef\\u4ee5\\u6839\\u64da\\u9700\\u8981\\u4fee\\u6539 `n` \\u7684\\u503c\\u4f86\\u8a08\\u7b97\\u4e0d\\u540c\\u9577\\u5ea6\\u7684\\u8cbb\\u6c0f\\u6578\\u5217\\u3002\",\n",
      "        \"refusal\": null,\n",
      "        \"reasoning\": null\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 198,\n",
      "    \"completion_tokens\": 274,\n",
      "    \"total_tokens\": 472\n",
      "  }\n",
      "}\n",
      "✅ 模型回覆內容：\n",
      "當然可以！費氏數列是一個著名的數學序列，其中每個數字是前兩個數字的總和。通常從0和1或1和1開始。以下是一段Python程式碼，計算費氏數列的前N個數字：\n",
      "\n",
      "```python\n",
      "def fibonacci(n):\n",
      "    if n <= 0:\n",
      "        return []\n",
      "    elif n == 1:\n",
      "        return [0]\n",
      "    elif n == 2:\n",
      "        return [0, 1]\n",
      "\n",
      "    fib_sequence = [0, 1]\n",
      "    for i in range(2, n):\n",
      "        next_value = fib_sequence[-1] + fib_sequence[-2]\n",
      "        fib_sequence.append(next_value)\n",
      "\n",
      "    return fib_sequence\n",
      "\n",
      "# 範例使用\n",
      "n = 10  # 假設我們要計算前10個費氏數列數字\n",
      "fib_sequence = fibonacci(n)\n",
      "print(f\"The first {n} Fibonacci numbers are: {fib_sequence}\")\n",
      "```\n",
      "\n",
      "這段程式碼定義了一個函數 `fibonacci(n)`，會返回費氏數列的前N個數字。你可以根據需要修改 `n` 的值來計算不同長度的費氏數列。\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "# 設定 OpenRouter 的 API 金鑰與網址\n",
    "openai.api_key = \"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\"  # ← 記得\n",
    "openai.api_base = \"https://openrouter.ai/api/v1\"\n",
    "\n",
    "# 呼叫 API\n",
    "try:\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"mistralai/mistral-small-3.1-24b-instruct:free\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"幫我寫一段 Python 程式碼，計算費氏數列。\"},\n",
    "        ]\n",
    "    )\n",
    "    print(\"✅ API 呼叫成功，回傳內容如下：\")\n",
    "    print(json.dumps(response, indent=2))  # 🔍 印出完整 response 結構，幫助除錯\n",
    "\n",
    "    # 嘗試取得內容\n",
    "    if \"choices\" in response:\n",
    "        content = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "        print(\"✅ 模型回覆內容：\")\n",
    "        print(content)\n",
    "    else:\n",
    "        print(\"⚠️ API 回傳中沒有 'choices' 欄位，可能是錯誤訊息\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ 發生錯誤：{e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "afad254e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"gen-1744262757-R189lbVuM9rpL7A0krmP\",\n",
      "  \"provider\": \"Chutes\",\n",
      "  \"model\": \"mistralai/mistral-small-3.1-24b-instruct\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1744262757,\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"logprobs\": null,\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"native_finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"\\u7576\\u7136\\u53ef\\u4ee5\\uff01\\u8cbb\\u6c0f\\u6578\\u5217\\u662f\\u4e00\\u500b\\u8457\\u540d\\u7684\\u6578\\u5b78\\u5e8f\\u5217\\uff0c\\u5176\\u4e2d\\u6bcf\\u500b\\u6578\\u5b57\\u662f\\u524d\\u5169\\u500b\\u6578\\u5b57\\u7684\\u7e3d\\u548c\\u3002\\u901a\\u5e38\\u5f9e0\\u548c1\\u62161\\u548c1\\u958b\\u59cb\\u3002\\u4ee5\\u4e0b\\u662f\\u4e00\\u6bb5Python\\u7a0b\\u5f0f\\u78bc\\uff0c\\u8a08\\u7b97\\u8cbb\\u6c0f\\u6578\\u5217\\u7684\\u524dN\\u500b\\u6578\\u5b57\\uff1a\\n\\n```python\\ndef fibonacci(n):\\n    if n <= 0:\\n        return []\\n    elif n == 1:\\n        return [0]\\n    elif n == 2:\\n        return [0, 1]\\n\\n    fib_sequence = [0, 1]\\n    for i in range(2, n):\\n        next_value = fib_sequence[-1] + fib_sequence[-2]\\n        fib_sequence.append(next_value)\\n\\n    return fib_sequence\\n\\n# \\u7bc4\\u4f8b\\u4f7f\\u7528\\nn = 10  # \\u5047\\u8a2d\\u6211\\u5011\\u8981\\u8a08\\u7b97\\u524d10\\u500b\\u8cbb\\u6c0f\\u6578\\u5217\\u6578\\u5b57\\nfib_sequence = fibonacci(n)\\nprint(f\\\"The first {n} Fibonacci numbers are: {fib_sequence}\\\")\\n```\\n\\n\\u9019\\u6bb5\\u7a0b\\u5f0f\\u78bc\\u5b9a\\u7fa9\\u4e86\\u4e00\\u500b\\u51fd\\u6578 `fibonacci(n)`\\uff0c\\u6703\\u8fd4\\u56de\\u8cbb\\u6c0f\\u6578\\u5217\\u7684\\u524dN\\u500b\\u6578\\u5b57\\u3002\\u4f60\\u53ef\\u4ee5\\u6839\\u64da\\u9700\\u8981\\u4fee\\u6539 `n` \\u7684\\u503c\\u4f86\\u8a08\\u7b97\\u4e0d\\u540c\\u9577\\u5ea6\\u7684\\u8cbb\\u6c0f\\u6578\\u5217\\u3002\",\n",
      "        \"refusal\": null,\n",
      "        \"reasoning\": null\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 198,\n",
      "    \"completion_tokens\": 274,\n",
      "    \"total_tokens\": 472\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(response, indent=2))  # 這個印出來的結果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2187ebe9-cca5-42d3-badd-7d0d21f02900",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os \n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR-API-KEY\"\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    openai_api_key = os.environ[\"OPENAI_API_KEY\"],\n",
    "    model = 'gpt-3.5-turbo'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e096c1b7-e3c7-4b6d-89ef-7dd8f836c5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import (\n",
    "    SystemMessage,\n",
    "    HumanMessage,\n",
    "    AIMessage\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content = \"Knock knock.\"),\n",
    "    AIMessage(content = \"Who's there?\"),\n",
    "    HumanMessage(content=\"Orange\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f2afff4a-e7e4-4cc4-ac50-f46492b41dd2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "No auth credentials found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m res\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages\\langchain\\chat_models\\base.py:606\u001b[0m, in \u001b[0;36mBaseChatModel.__call__\u001b[1;34m(self, messages, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m    600\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    601\u001b[0m     messages: List[BaseMessage],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    605\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m--> 606\u001b[0m     generation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m    607\u001b[0m         [messages], stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    608\u001b[0m     )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    609\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(generation, ChatGeneration):\n\u001b[0;32m    610\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages\\langchain\\chat_models\\base.py:355\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[0;32m    353\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[0;32m    354\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e)\n\u001b[1;32m--> 355\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    356\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    357\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[0;32m    359\u001b[0m ]\n\u001b[0;32m    360\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages\\langchain\\chat_models\\base.py:345\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    344\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 345\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    346\u001b[0m                 m,\n\u001b[0;32m    347\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    348\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    349\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    350\u001b[0m             )\n\u001b[0;32m    351\u001b[0m         )\n\u001b[0;32m    352\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    353\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages\\langchain\\chat_models\\base.py:498\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    494\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    495\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    496\u001b[0m     )\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported:\n\u001b[1;32m--> 498\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m    499\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    500\u001b[0m     )\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages\\langchain\\chat_models\\openai.py:360\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[1;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[0;32m    358\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[0;32m    359\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[1;32m--> 360\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompletion_with_retry(\n\u001b[0;32m    361\u001b[0m     messages\u001b[38;5;241m=\u001b[39mmessage_dicts, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    362\u001b[0m )\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages\\langchain\\chat_models\\openai.py:299\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry\u001b[1;34m(self, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_completion_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _completion_with_retry(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages\\tenacity\\__init__.py:336\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    334\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    335\u001b[0m wrapped_f\u001b[38;5;241m.\u001b[39mstatistics \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mstatistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m--> 336\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m copy(f, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages\\tenacity\\__init__.py:475\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    473\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 475\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    477\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages\\tenacity\\__init__.py:376\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    374\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[1;32m--> 376\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages\\tenacity\\__init__.py:398\u001b[0m, in \u001b[0;36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[1;34m(rs)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetryCallState\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mis_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mretry_run_result):\n\u001b[1;32m--> 398\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutcome\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    399\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    401\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages\\tenacity\\__init__.py:478\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 478\u001b[0m         result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[0;32m    480\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages\\langchain\\chat_models\\openai.py:297\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry.<locals>._completion_with_retry\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_completion_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m--> 297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:155\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    139\u001b[0m ):\n\u001b[0;32m    140\u001b[0m     (\n\u001b[0;32m    141\u001b[0m         deployment_id,\n\u001b[0;32m    142\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    152\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    153\u001b[0m     )\n\u001b[1;32m--> 155\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[0;32m    166\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[0;32m    167\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages\\openai\\api_requestor.py:299\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    280\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    287\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    288\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    289\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[0;32m    290\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[0;32m    291\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    297\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[0;32m    298\u001b[0m     )\n\u001b[1;32m--> 299\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    300\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages\\openai\\api_requestor.py:710\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    702\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    703\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    704\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    705\u001b[0m         )\n\u001b[0;32m    706\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[0;32m    707\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    708\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    709\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 710\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    711\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    712\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    714\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    715\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    716\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    717\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages\\openai\\api_requestor.py:775\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    773\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m    774\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m--> 775\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[0;32m    776\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[0;32m    777\u001b[0m     )\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mAuthenticationError\u001b[0m: No auth credentials found"
     ]
    }
   ],
   "source": [
    "res = chat(messages)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61112f7-f8af-4145-8f6c-50c0d039a0f8",
   "metadata": {},
   "source": [
    "## 用OpenRouter的 mistralai/mistral-small-3.1-24b-instruct:free 語言模型 實作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a16050f9-74e8-45a8-8a62-cfa05f2372a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import (\n",
    "    SystemMessage,\n",
    "    HumanMessage,\n",
    "    AIMessage\n",
    ")\n",
    "import os\n",
    "\n",
    "# 設定 API 金鑰與 OpenRouter 的 base url\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "# 建立 ChatOpenAI，支援 OpenRouter\n",
    "chat = ChatOpenAI(\n",
    "    openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    openai_api_base=\"https://openrouter.ai/api/v1\",\n",
    "    model=\"mistralai/mistral-small-3.1-24b-instruct:free\"\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3d23584e-9327-4563-8705-7f5b6424db37",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'choices'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 10\u001b[0m\n\u001b[0;32m      2\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      3\u001b[0m     SystemMessage(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a helpful assistant.\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      4\u001b[0m     HumanMessage(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m敲敲門\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      5\u001b[0m     AIMessage(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m誰在搞?\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      6\u001b[0m     HumanMessage(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m我啦，人類\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      7\u001b[0m ]\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# 發送對話\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# 印出回答\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(res\u001b[38;5;241m.\u001b[39mcontent)\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages\\langchain\\chat_models\\base.py:606\u001b[0m, in \u001b[0;36mBaseChatModel.__call__\u001b[1;34m(self, messages, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m    600\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    601\u001b[0m     messages: List[BaseMessage],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    605\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m--> 606\u001b[0m     generation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m    607\u001b[0m         [messages], stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    608\u001b[0m     )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    609\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(generation, ChatGeneration):\n\u001b[0;32m    610\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages\\langchain\\chat_models\\base.py:355\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[0;32m    353\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[0;32m    354\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e)\n\u001b[1;32m--> 355\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    356\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    357\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[0;32m    359\u001b[0m ]\n\u001b[0;32m    360\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages\\langchain\\chat_models\\base.py:345\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    344\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 345\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    346\u001b[0m                 m,\n\u001b[0;32m    347\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    348\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    349\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    350\u001b[0m             )\n\u001b[0;32m    351\u001b[0m         )\n\u001b[0;32m    352\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    353\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages\\langchain\\chat_models\\base.py:498\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    494\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    495\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    496\u001b[0m     )\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported:\n\u001b[1;32m--> 498\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m    499\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    500\u001b[0m     )\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages\\langchain\\chat_models\\openai.py:363\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[1;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[0;32m    359\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[0;32m    360\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompletion_with_retry(\n\u001b[0;32m    361\u001b[0m     messages\u001b[38;5;241m=\u001b[39mmessage_dicts, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    362\u001b[0m )\n\u001b[1;32m--> 363\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_chat_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages\\langchain\\chat_models\\openai.py:378\u001b[0m, in \u001b[0;36mChatOpenAI._create_chat_result\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_create_chat_result\u001b[39m(\u001b[38;5;28mself\u001b[39m, response: Mapping[\u001b[38;5;28mstr\u001b[39m, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatResult:\n\u001b[0;32m    377\u001b[0m     generations \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 378\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchoices\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[0;32m    379\u001b[0m         message \u001b[38;5;241m=\u001b[39m convert_dict_to_message(res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    380\u001b[0m         gen \u001b[38;5;241m=\u001b[39m ChatGeneration(\n\u001b[0;32m    381\u001b[0m             message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[0;32m    382\u001b[0m             generation_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(finish_reason\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinish_reason\u001b[39m\u001b[38;5;124m\"\u001b[39m)),\n\u001b[0;32m    383\u001b[0m         )\n",
      "\u001b[1;31mKeyError\u001b[0m: 'choices'"
     ]
    }
   ],
   "source": [
    "# 多輪對話訊息（System、User、AI 模擬歷史對話）\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"敲敲門\"),\n",
    "    AIMessage(content=\"誰在搞?\"),\n",
    "    HumanMessage(content=\"我啦，人類\"),\n",
    "]\n",
    "\n",
    "# 發送對話\n",
    "res = chat(messages)\n",
    "\n",
    "# 印出回答\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3bd994d5-ef90-4e91-bbe3-53aacd56f508",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 重新儲存 新對話\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"Knock knock.\"),\n",
    "    AIMessage(content=\"Who's there?\"),\n",
    "    HumanMessage(content=\"Orange\"),\n",
    "    AIMessage(content=\"Orange who? Orange you going to let me in?\"),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42ecd550-88e4-4a45-ab52-34ffdf0902c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It seems we are playing a game of knock knock!\n",
      "\n",
      "So let's start again.\n",
      "\n",
      "Knock knock.\n",
      "\n",
      "(You go!)\n"
     ]
    }
   ],
   "source": [
    "# 新增一輪對話\n",
    "messages.append(HumanMessage(content=\"Who's there?\"))\n",
    "\n",
    "# 發送對話並印出回答\n",
    "response = chat(messages)\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c19a1bb-4835-4596-9269-a8faae5c224e",
   "metadata": {},
   "source": [
    "## 處理LLM存在的缺陷\n",
    "\n",
    "### 1.容易出現幻覺\n",
    "### 2.信息滯後\n",
    "### 3.專業領域深度匱乏"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5857a467-08ea-4713-8ae0-a5529aae5ce4",
   "metadata": {},
   "source": [
    "#### 新的對話"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcb9b653-a6f4-46bb-a5d7-989d34254255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "是的，我知道 ChatGPT 模型。ChatGPT 是由 OpenAI 开发的一款基于大型语言模型的对话生成系统。它利用深度学习技术，特别是变换器（Transformer）架构，来理解和生成自然语言文本。ChatGPT 能够进行多种对话任务，包括回答问题、提供信息、编写文本、翻译语言等。\n",
      "\n",
      "ChatGPT 的训练数据来源于大量的互联网文本，因此它能够处理广泛的主题和问题。然而，它的知识截止到2023年10月，无法实时获取最新的信息。此外，它可能会在某些情况下生成不准确或不可靠的信息，因此使用时需要谨慎。\n",
      "\n",
      "如果你有任何具体的问题或需要进一步的信息，请告诉我！\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"你是一個專業的知識助手。\"),\n",
    "    HumanMessage(content=\"你知道chatgpt模型嗎?\"),\n",
    "]\n",
    "\n",
    "res = chat(messages)\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92c4af2-6763-4969-8efa-37c83741c319",
   "metadata": {},
   "source": [
    "### 其實有發現mistralai/mistral-small-3.1-24b-instruct:free 語言模型無法滿足我們在某些特定領域的專業需求，我們可以通過知識注入的方式，利用prompt來解決問題:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4ffca2-0c9c-4ed8-8c21-18ed91183c85",
   "metadata": {},
   "source": [
    "<img src=\"picture/wiki.jpg\" width=\"800\" height=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4f0f38c5-3b7a-4e46-949b-903b1a420afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ChatGPT_information = [\n",
    "    \"ChatGPT，全稱聊天生成預訓練轉換器（英語：Chat Generative Pre-trained Transformer），是OpenAI開發的人工智慧聊天機器人程式，於2022年12月推出。\",\n",
    "    \"該程式使用基於GPT-3.5、GPT-4、GPT-4o、GPT-4.5架構的大型語言模型並以強化學習訓練。\",\n",
    "    \"ChatGPT目前仍以文字方式互動，而除了可以用人類自然對話方式來互動，還可以用於甚為複雜的語言工作，包括自動生成文字、自動問答、自動摘要等多種任務。\",\n",
    "    \"如：在自動文字生成方面，ChatGPT可以根據輸入的文字自動生成類似的文字（劇本、歌曲、企劃等），在自動問答方面，ChatGPT可以根據輸入的問題自動生成答案。\",\n",
    "    \"還有編寫和除錯電腦程式的能力。\",\n",
    "    \"在推廣期間，所有人可以免費註冊，並在登入後免費使用ChatGPT與AI機器人對話。\",\n",
    "    \"ChatGPT可寫出相似真人的文章，並在許多知識領域給出詳細和清晰的回答而迅速獲得關注，證明了從前認為AI不會取代的知識型工作它也足以勝任，對金融與白領人力市場的衝擊相當大，並在逐步提升取代醫療人力的能力，以提供比人類更佳的診斷。\",\n",
    "    \"但也認為事實準確度參差不齊是其重大缺陷，並認為基於意識形態的模型訓練結果須小心校正。\",\n",
    "    \"ChatGPT於2022年12月發布後，OpenAI估值已漲至290億美元。\",\n",
    "    \"上線5天後已有100萬使用者，上線兩個月後已有上億使用者。\",\n",
    "    \"目前GPT-3.5（現升級為GPT-4o mini）為免費使用，無需註冊，GPT-4o對已註冊免費使用者開放使用，但有使用量限制。\",\n",
    "    \"註冊的ChatGPT免費使用者都可以使用瀏覽、視覺、資料分析、檔案上傳和GPTs等原付費使用者的功能，但有使用量限制。\",\n",
    "    \"雖然ChatGPT在生成類人文字方面表現出了卓越的能力，但它們很容易繼承和放大訓練資料中存在的偏差。\",\n",
    "    \"這可能表現為對不同人口統計資料的歪曲表述或不公平待遇，例如基於種族、性別、語言和文化群體的不同觀點與態度。\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "826de2b6-cacb-43a3-9acb-2d49f2c04f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_knowledge = \"\\n\".join(ChatGPT_information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f6b7db5e-9b87-427d-898a-11fed28ec2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT，全稱聊天生成預訓練轉換器（英語：Chat Generative Pre-trained Transformer），是OpenAI開發的人工智慧聊天機器人程式，於2022年12月推出。\n",
      "該程式使用基於GPT-3.5、GPT-4、GPT-4o、GPT-4.5架構的大型語言模型並以強化學習訓練。\n",
      "ChatGPT目前仍以文字方式互動，而除了可以用人類自然對話方式來互動，還可以用於甚為複雜的語言工作，包括自動生成文字、自動問答、自動摘要等多種任務。\n",
      "如：在自動文字生成方面，ChatGPT可以根據輸入的文字自動生成類似的文字（劇本、歌曲、企劃等），在自動問答方面，ChatGPT可以根據輸入的問題自動生成答案。\n",
      "還有編寫和除錯電腦程式的能力。\n",
      "在推廣期間，所有人可以免費註冊，並在登入後免費使用ChatGPT與AI機器人對話。\n",
      "ChatGPT可寫出相似真人的文章，並在許多知識領域給出詳細和清晰的回答而迅速獲得關注，證明了從前認為AI不會取代的知識型工作它也足以勝任，對金融與白領人力市場的衝擊相當大，並在逐步提升取代醫療人力的能力，以提供比人類更佳的診斷。\n",
      "但也認為事實準確度參差不齊是其重大缺陷，並認為基於意識形態的模型訓練結果須小心校正。\n",
      "ChatGPT於2022年12月發布後，OpenAI估值已漲至290億美元。\n",
      "上線5天後已有100萬使用者，上線兩個月後已有上億使用者。\n",
      "目前GPT-3.5（現升級為GPT-4o mini）為免費使用，無需註冊，GPT-4o對已註冊免費使用者開放使用，但有使用量限制。\n",
      "註冊的ChatGPT免費使用者都可以使用瀏覽、視覺、資料分析、檔案上傳和GPTs等原付費使用者的功能，但有使用量限制。\n",
      "雖然ChatGPT在生成類人文字方面表現出了卓越的能力，但它們很容易繼承和放大訓練資料中存在的偏差。\n",
      "這可能表現為對不同人口統計資料的歪曲表述或不公平待遇，例如基於種族、性別、語言和文化群體的不同觀點與態度。\n"
     ]
    }
   ],
   "source": [
    "print(source_knowledge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7957a5d7-96a0-4260-a17e-8743a52f47fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"你知道ChatGPT模型嗎\"\n",
    "prompt_template = f\"\"\"基於以下內容回答問題:\n",
    "內容:\n",
    "{source_knowledge}\n",
    "\n",
    "Query: {query}\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "49dd1350-fdc2-421a-b6ac-b293403c87b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = HumanMessage(\n",
    "    content = prompt_template\n",
    ")\n",
    "messages.append(prompt)\n",
    "\n",
    "res = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "14fb35ad-ae4d-4a54-b45b-eee7122e9b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "是的，我知道ChatGPT模型。ChatGPT是由OpenAI開發的一種基於GPT（Generative Pre-trained Transformer）架構的大型語言模型，旨在進行自然語言處理和生成。以下是一些關鍵點：\n",
      "\n",
      "1. **發布時間**：ChatGPT於2022年12月推出。\n",
      "2. **技術基礎**：ChatGPT基於GPT-3.5、GPT-4、GPT-4o和GPT-4.5等架構，並通過強化學習進行訓練。\n",
      "3. **功能**：ChatGPT能夠進行多種語言任務，包括自動生成文字、自動問答、自動摘要、編寫和除錯電腦程式等。\n",
      "4. **使用方式**：目前ChatGPT主要通過文字方式與用戶互動，能夠模擬人類自然對話。\n",
      "5. **應用範圍**：ChatGPT可以用於多種知識型工作，包括劇本、歌曲、企劃的生成，並能在金融、醫療等領域提供支持。\n",
      "6. **免費使用**：在推廣期間，所有人可以免費註冊並使用ChatGPT。GPT-3.5（現升級為GPT-4o mini）為免費使用，GPT-4o則對已註冊免費使用者開放，但有使用量限制。\n",
      "7. **缺陷與挑戰**：儘管ChatGPT表現出色，但其生成的內容可能存在事實準確度問題，並可能繼承和放大訓練資料中的偏差，如種族、性別、語言和文化群體的歪曲表述或不公平待遇。\n",
      "\n",
      "總的來說，ChatGPT是一種功能強大且具有廣泛應用前景的語言模型，但也需要注意其潛在的偏差和準確性問題。\n"
     ]
    }
   ],
   "source": [
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b1c989-07ef-4718-9ae1-39d2045cd5d7",
   "metadata": {},
   "source": [
    "### 發現，當我們進行知識的注入後，模型就能很好的回答相關問題。如果每一個問題都去用外部知識進行增強與拚解的話，那麼回答的準確性就能大大增加嗎?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cf1ed5-6b4b-4638-b066-d609c02982ce",
   "metadata": {},
   "source": [
    "## 創建一個RAG的對話模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6012dd1-ff92-4b81-a0a5-35292db1e2ce",
   "metadata": {},
   "source": [
    "<img src=\"picture/rag flow.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4c6671-bd73-49a8-bee3-2920e20f6e60",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### 1.加載數據"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4906aaa1-a004-4885-a115-445b6a1b9d8d",
   "metadata": {},
   "source": [
    "thesis_.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dab1f8f2-22be-4c3c-8846-fafdb25c1517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (5.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from pypdf) (4.13.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "16f88be8-a5d2-4317-bd89-81607c7bd400",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# 直接寫路徑，假設 PDF 檔案與腳本在同一資料夾\n",
    "loader = PyPDFLoader(\"./thesis__.pdf\")\n",
    "\n",
    "# 載入並分割頁面\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38c0c4bc-5ebd-4e9d-8136-143e8987d73e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='國立成功大學 \\n系統及船舶機電工程學系 \\n碩士論文 \\n熱成像技術於鋰電池未知熱源之預測 \\nThe Estimation of Unknown Transient Heat\\nGeneration for Lithium Battery with \\nThermography Techniques  \\n研 究 生： 林子揚 \\n指導教授： 黃正弘 \\n中華民國一百一十三年十二月', metadata={'source': './thesis__.pdf', 'page': 0})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794d6c4f-bed0-4370-b32f-685a22a08157",
   "metadata": {},
   "source": [
    "### 2.知識切片 將文檔分割成均勻的塊。 每個塊是一段原始文本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a8961cf2-1b06-47f7-8c40-16c867620ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap =50,\n",
    ")\n",
    "\n",
    "docs = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f4ba87a-ba35-4d00-949d-a9ecf7a7ab4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ae8f9b-2024-4b2f-a753-add96db7ed9d",
   "metadata": {},
   "source": [
    "### 3.利用embedding模型對每個文本片段進行向量化，並儲存到向量數據庫中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2c728d0d-8d57-42db-9030-ff3e5c862190",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (0.0.316)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (4.0.2)\n",
      "Requirement already satisfied: transformers in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (4.51.1)\n",
      "Requirement already satisfied: chromadb in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (0.4.15)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from langchain) (2.0.40)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from langchain) (3.11.16)\n",
      "Requirement already satisfied: anyio<4.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from langchain) (3.7.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from langchain) (0.6.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.43 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from langchain) (0.0.92)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from langchain) (2.11.3)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from sentence-transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from sentence-transformers) (0.30.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from sentence-transformers) (4.13.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from chromadb) (0.7.3)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from chromadb) (0.115.12)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
      "Requirement already satisfied: posthog>=2.4.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from chromadb) (3.23.0)\n",
      "Requirement already satisfied: pulsar-client>=3.1.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from chromadb) (3.6.1)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from chromadb) (1.21.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from chromadb) (1.31.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from chromadb) (1.31.1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from chromadb) (1.31.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from chromadb) (1.71.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from chromadb) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from chromadb) (0.15.2)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from chromadb) (32.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.19.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from anyio<4.0->langchain) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from anyio<4.0->langchain) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from anyio<4.0->langchain) (1.2.2)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from fastapi>=0.95.2->chromadb) (0.46.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (3.0.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2025.1.31)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
      "Requirement already satisfied: protobuf in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (5.29.4)\n",
      "Requirement already satisfied: sympy in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.6.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.69.2)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.31.1 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.31.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.31.1 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.31.1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.52b1 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.52b1)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from typer>=0.9.0->chromadb) (14.0.0)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.6.3 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.5)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from deprecated>=1.2.6->opentelemetry-api>=1.2.0->chromadb) (1.17.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (2.19.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.5.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install langchain sentence-transformers transformers chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "542de967-3fd3-47e7-b4cc-7e163daa8f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "\n",
    "\n",
    "# 创建HuggingFace embedding模型\n",
    "# 这里使用多语言模型，对中文效果很好\n",
    "embed_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    ")\n",
    "\n",
    "# 创建向量存储\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=docs, \n",
    "    embedding=embed_model,\n",
    "    collection_name=\"hf_embeddings\",\n",
    "    persist_directory=\"./chroma_db2\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "22a3a6b4-3e9b-429c-8b50-825428a91141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 示例搜索\n",
    "query = \"作者使用的 商業軟體是甚麼?\"\n",
    "results = vectorstore.similarity_search(query, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "78d78520-96d3-423b-aaaf-4662f927996a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='裝軟體強大的正算能力來彌補傳統逆向問題之不足。本論文所使用的套裝\\n軟體為三維耦合計算流體力學軟體CFD-ACE+，軟體為 ESI-GROUP 所發\\n行，其提供了一系列包含前處理(GEOM)，數值計算(ACE+)及後處理(VIEW)\\n等三大模組，使其擁有完整且強大的正算問題處理能力。 \\n在第二章及第三章吾人利用此軟體來模擬圓柱型鋰電池內部熱源發', metadata={'page': 21, 'source': './thesis__.pdf'}),\n",
       " Document(page_content='1 \\n \\n致謝 \\n在我整個研究的過程中，黃正弘教授的悉心指導和無私支持讓我深\\n感榮幸，也讓我受益匪淺。回顧這段時間，我從一名對研究領域懵懂的學\\n生，成長為能夠獨立思考和解決問題的研究者，更或者是實驗室學弟妹的\\n諮詢對象(程式及實驗)，這一切都離不開黃教授的耐心教導和持續的激勵 \\n。教授以其豐富的學識、嚴謹的學術態度以及對教育的熱忱，使我在專業\\n領域上不斷精進。每當我遇到困難或感到迷茫時，教授總是會重新不斷激\\n勵我，並及時提供最具建設性的建議或找尋外部資源，幫助我找到解決問\\n題的方向(電池的電學、自動化資料後處理、系統指令)，同時藉由接觸更\\n多面向的專業知識來解決無法由原先思路去解決的問題。在這段時間裡，\\n我學會了如何冷靜分析問題、蒐集資料、找尋專家來探索答案，並始終保\\n持對知識的渴求和對事物的好奇心。 \\n也謝謝岱冠科技有限公司連奕輔副理在商業套裝軟體 ESI-CFD 的功\\n能諮詢，特別是在處理複雜度較高的暫態問題上，細心回覆我一些不常使\\n用的特殊功能。還有洲通能源科技有限公司林建成業務在電池充放電測\\n試主機BAT-760B 的諮詢，協助我架構出電池放電實驗。及富力電能有限', metadata={'page': 9, 'source': './thesis__.pdf'})]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c6045e-2974-45f8-90bc-74b742b11913",
   "metadata": {},
   "source": [
    "### 5.原始query與檢索得到的文本組合起來輸入到語言模型，得到最終的回答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d24fc029-f2ef-4fd4-afdc-706d7343e305",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_prompt(query: str):\n",
    "    # 獲取top3的文本片段\n",
    "    results = vectorstore.similarity_search(query, k=3)\n",
    "    source_knowledge = \"\\n\".join([x.page_content for x in results])\n",
    "    # 構建prompt\n",
    "    augmented_prompt = f\"\"\"Using the contexts below, answer the query.\n",
    "\n",
    "    contexts:\n",
    "    {source_knowledge}\n",
    "\n",
    "    query: {query}\"\"\"\n",
    "    return augmented_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f5e0c59d-070d-463d-8213-37bcf250c937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the contexts below, answer the query.\n",
      "\n",
      "    contexts:\n",
      "    裝軟體強大的正算能力來彌補傳統逆向問題之不足。本論文所使用的套裝\n",
      "軟體為三維耦合計算流體力學軟體CFD-ACE+，軟體為 ESI-GROUP 所發\n",
      "行，其提供了一系列包含前處理(GEOM)，數值計算(ACE+)及後處理(VIEW)\n",
      "等三大模組，使其擁有完整且強大的正算問題處理能力。 \n",
      "在第二章及第三章吾人利用此軟體來模擬圓柱型鋰電池內部熱源發\n",
      "1 \n",
      " \n",
      "致謝 \n",
      "在我整個研究的過程中，黃正弘教授的悉心指導和無私支持讓我深\n",
      "感榮幸，也讓我受益匪淺。回顧這段時間，我從一名對研究領域懵懂的學\n",
      "生，成長為能夠獨立思考和解決問題的研究者，更或者是實驗室學弟妹的\n",
      "諮詢對象(程式及實驗)，這一切都離不開黃教授的耐心教導和持續的激勵 \n",
      "。教授以其豐富的學識、嚴謹的學術態度以及對教育的熱忱，使我在專業\n",
      "領域上不斷精進。每當我遇到困難或感到迷茫時，教授總是會重新不斷激\n",
      "勵我，並及時提供最具建設性的建議或找尋外部資源，幫助我找到解決問\n",
      "題的方向(電池的電學、自動化資料後處理、系統指令)，同時藉由接觸更\n",
      "多面向的專業知識來解決無法由原先思路去解決的問題。在這段時間裡，\n",
      "我學會了如何冷靜分析問題、蒐集資料、找尋專家來探索答案，並始終保\n",
      "持對知識的渴求和對事物的好奇心。 \n",
      "也謝謝岱冠科技有限公司連奕輔副理在商業套裝軟體 ESI-CFD 的功\n",
      "能諮詢，特別是在處理複雜度較高的暫態問題上，細心回覆我一些不常使\n",
      "用的特殊功能。還有洲通能源科技有限公司林建成業務在電池充放電測\n",
      "試主機BAT-760B 的諮詢，協助我架構出電池放電實驗。及富力電能有限\n",
      "用程式語言Python 配合文字編輯軟體Notepad++將所需之熱源編寫於文字\n",
      "檔.TXT。 \n",
      "(3) 撰寫供DTF 檔連結的DLL 檔 ， 共有四個DLL 檔 ， 分別是EXACTG\n",
      "所需的 DLL 檔、DIR 所需的 DLL 檔、ADJ 所需的 DLL 檔及 SEN 所需的\n",
      "DLL 檔。EXACTG、MAIN、SEN 的DLL 檔可以使圓柱中不同體積的網格\n",
      "\n",
      "    query: 作者使用的 商業軟體是甚麼?\n"
     ]
    }
   ],
   "source": [
    "print(augment_prompt(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "be2d8c64-4a79-45de-bfde-2e0b7024e81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "作者使用的商業軟體是 **ESI-CFD**。這個軟體由 ESI Group 發行，具體來說，作者使用的是其三維耦合計算流體力學軟體 **CFD-ACE+**。ESI-CFD 提供了前處理（GEOM）、數值計算（ACE+）及後處理（VIEW）等三大模組，使其擁有完整且強大的正算問題處理能力。\n"
     ]
    }
   ],
   "source": [
    "# 創建 prompt\n",
    "prompt = HumanMessage(\n",
    "    content = augment_prompt(query)\n",
    ")\n",
    "\n",
    "messages.append(prompt)\n",
    "\n",
    "res = chat(messages)\n",
    "\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26da11aa-ab15-4af8-adb7-903448f73cf1",
   "metadata": {},
   "source": [
    "## 沒有OPENAI api key怎麼辦 創建一個非openai的對話模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772c9366-5963-4a2d-87ca-2530c849aebd",
   "metadata": {},
   "source": [
    "### 1.embedding模型\n",
    "### 2.chat模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aeec31fc-cc2a-4152-bae5-983176ce4293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (4.0.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from sentence-transformers) (4.51.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from sentence-transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from sentence-transformers) (0.30.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from sentence-transformers) (4.13.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\roy\\anaconda3\\envs\\rag\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "! pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3c820506-2a7e-4925-9abb-dc060ada0c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "model_name= \"sentence-transformers/sentence-t5-large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b867da64-08f3-470c-bbb8-f7bfaa7adc7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hf_xet\n",
      "  Downloading hf_xet-1.0.2-cp37-abi3-win_amd64.whl.metadata (498 bytes)\n",
      "Downloading hf_xet-1.0.2-cp37-abi3-win_amd64.whl (4.1 MB)\n",
      "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.5/4.1 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 3.1/4.1 MB 10.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.1/4.1 MB 9.9 MB/s eta 0:00:00\n",
      "Installing collected packages: hf_xet\n",
      "Successfully installed hf_xet-1.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install hf_xet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9ebc2b95-e170-43e3-a6ae-fc8f3ad4205f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cf3ada57-a7cf-4b98-9fe4-801e854c7c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = HuggingFaceEmbeddings(model_name = model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "aeb27f07-c051-4577-82da-42ed186c7593",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectorstore_hf = Chroma.from_documents(documents=docs, embedding = embedding , collection_name = \"huggingface_embed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffa2c14-c27b-474f-85f4-9fa2554c5296",
   "metadata": {},
   "source": [
    "### 也可以用GPU(之後再用)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06dae3a-4dbd-4148-a407-380dbbd9cf64",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=KW-iKts6E8M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43835247-38e0-43ec-a472-7d8f4cd79679",
   "metadata": {},
   "source": [
    "### 回到正題"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8e00669e-eaa6-4f90-9704-5e13bb46071d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 示例搜索\n",
    "query = \"How large is the baichuan2 vocavulary?\"\n",
    "result = vectorstore_hf.similarity_search(query, k =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "90d3d9ea-1f80-46e0-9a56-2756cdb17b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='Baichuan 2: Open Large-scale Language Models\\nAiyuan Yang, Bin Xiao, Bingning Wang, Borong Zhang, Chao Yin, Chenxu Lv, Da Pan\\nDian Wang, Dong Yan, Fan Yang, Fei Deng, Feng Wang, Feng Liu, Guangwei Ai\\nGuosheng Dong, Haizhou Zhao, Hang Xu, Haoze Sun, Hongda Zhang, Hui Liu, Jiaming Ji\\nJian Xie, Juntao Dai, Kun Fang, Lei Su, Liang Song, Lifeng Liu, Liyun Ru, Luyao Ma\\nMang Wang, Mickel Liu, MingAn Lin, Nuolan Nie, Peidong Guo, Ruiyang Sun', metadata={'page': 0, 'source': 'C:\\\\Users\\\\roy\\\\AppData\\\\Local\\\\Temp\\\\tmplwua9z6z\\\\tmp.pdf'}), Document(page_content='languages, such as Chinese.\\nIn this technical report, we introduce Baichuan\\n2, a series of large-scale multilingual language\\nmodels. Baichuan 2 has two separate models,\\nBaichuan 2-7B with 7 billion parameters and\\nBaichuan 2-13B with 13 billion parameters. Both\\nmodels were trained on 2.6 trillion tokens, which\\nto our knowledge is the largest to date, more than\\ndouble that of Baichuan 1 (Baichuan, 2023b,a).\\nWith such a massive amount of training data,', metadata={'page': 1, 'source': 'C:\\\\Users\\\\roy\\\\AppData\\\\Local\\\\Temp\\\\tmplwua9z6z\\\\tmp.pdf'})]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "524f6ae6-20e4-4d7b-8261-ac0e3ccd4f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_prompt(query: str):\n",
    "    # 獲取top3的文本片段\n",
    "    results = vectorstore.similarity_search(query, k=3)\n",
    "    source_knowledge = \"\\n\".join([x.page_content for x in results])\n",
    "    # 構建prompt\n",
    "    augmented_prompt = f\"\"\"Using the contexts below, answer the query.\n",
    "\n",
    "    contexts:\n",
    "    {source_knowledge}\n",
    "\n",
    "    query: {query}\"\"\"\n",
    "    return augmented_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "64e547e8-6656-4332-a20a-cde9a9f5570f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT 是 OpenAI 开发的一种人工智能聊天机器人程序，全称为聊天生成预训练转换器（Chat Generative Pre-trained Transformer）。它于 2022 年 12 月推出，基于 GPT-3.5、GPT-4、GPT-4o、GPT-4.5 架构的大型语言模型，并通过强化学习进行训练。ChatGPT 能够进行自然对话，并可用于复杂的语言任务，如自动生成文字、自动问答和自动摘要等。它还能编写和调试电脑程序。\n",
      "\n",
      "ChatGPT 的推广期间，所有人都可以免费注册并使用。它能够生成类似真人的文章，并在许多知识领域提供详细且清晰的回答。然而，ChatGPT 在事实准确度和意识形态方面可能存在偏差。\n",
      "\n",
      "关于 Baichuan 2 的词汇量，根据提供的背景信息，并没有直接提到 Baichuan 2 的词汇量大小。Baichuan 2 是一种大型多语言语言模型，有两个版本：Baichuan 2-7B（70亿参数）和 Baichuan 2-13B（130亿参数），两者都在 2.6 万亿个词汇上进行训练。如果需要具体的词汇量信息，可能需要参考 Baichuan 2 的技术报告或官方文档。\n"
     ]
    }
   ],
   "source": [
    "# 創建 prompt\n",
    "prompt = HumanMessage(\n",
    "    content = augment_prompt(query)\n",
    ")\n",
    "# 利用前面的 大語言模型繼續 問問題\n",
    "messages.append(prompt)\n",
    "\n",
    "res = chat(messages)\n",
    "\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c582b7ba-cd86-4a50-89c2-ef0f20682d56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
